# Learnings - neurealis ERP

**Stand:** 2026-02-02

---

## Marketing / Ads APIs

### L172 - Meta System User Token: App-Permissions erforderlich
**Datum:** 2026-02-02
**Kontext:** System User Token generieren f√ºr Meta Marketing API
**Problem:** "Keine Berechtigungen verf√ºgbar" beim Token generieren
**L√∂sung:**
1. App auf developers.facebook.com √∂ffnen
2. Marketing API Product hinzuf√ºgen/aktivieren
3. Unter "Anwendungsf√§lle" ‚Üí "Anpassen" ‚Üí Permissions aktivieren
4. Dann erst System User Token generieren
**Permissions f√ºr Ads:** `ads_read`, `ads_management`, `business_management`
**Wichtig:** System User braucht "Uneingeschr√§nkte Kontrolle" auf die App

### L171 - Meta Business Verification nicht immer n√∂tig
**Datum:** 2026-02-02
**Kontext:** Meta Ads API Integration
**Erkenntnis:** Business Verification ist NICHT f√ºr alle Unternehmen erforderlich
**Pr√ºfen:** Security Center ‚Üí "Verifizierung f√ºr [Business]"
**Wenn "nicht erforderlich":** Direkt mit API-Integration starten
**Wenn erforderlich:** 5+ Werktage einplanen, Dokumente bereithalten

### L170 - Meta App-Struktur: Use Cases statt Products
**Datum:** 2026-02-02
**Kontext:** Meta hat App-Dashboard umgestellt
**Alt:** "Produkte hinzuf√ºgen" ‚Üí Marketing API
**Neu:** "Anwendungsf√§lle" (Use Cases) ‚Üí "Werbeanzeigen erstellen und verwalten"
**Navigation:** App ‚Üí Use Cases ‚Üí Anpassen ‚Üí Berechtigungen aktivieren

---

## Kritische Feld-Mappings

### L169 - Hero-LV-Sync nur noch manuell (D048)
**Datum:** 2026-02-02
**Kontext:** Hero √ºberschrieb korrigierte Supabase-Preise mit veralteten Werten
**Problem:** Automatischer Cron `hero-lv-sync-daily` importierte niedrigere Hero-Preise
**L√∂sung:**
1. Cron deaktiviert: `SELECT cron.unschedule('hero-lv-sync-daily')`
2. Manueller Aufruf bei Bedarf: `curl .../functions/v1/hero-lv-sync`
3. Supabase ist jetzt LV-Master, nicht Hero
**Manueller Sync:**
```bash
curl "https://mfpuijttdgkllnvhvjlu.supabase.co/functions/v1/hero-lv-sync?dry_run=true"
```
**Wichtig:** Vor manuellem Sync IMMER dry_run pr√ºfen!

### L168 - Preishistorie-Trigger protokolliert automatisch
**Datum:** 2026-02-02
**Kontext:** LV-Preis√§nderungen m√ºssen nachvollziehbar sein
**L√∂sung:** Trigger `trg_lv_preis_historie` existiert und feuert bei UPDATE auf lv_positionen
**Tabelle:** `lv_preis_historie` mit:
- `listenpreis_alt`, `listenpreis_neu` (VK)
- `preis_alt`, `preis_neu` (EK)
- `aenderung_prozent`, `gueltig_ab`, `quelle`
**Vorteil:** Keine manuelle Dokumentation n√∂tig, alle Preis√§nderungen automatisch protokolliert

### L167 - GWS Preisimport-Workflow (Excel‚ÜíSupabase‚ÜíHero)
**Datum:** 2026-02-02
**Kontext:** GWS liefert aktualisierte Preise als Excel (Baupreisindex)
**Workflow:**
1. **Excel einlesen:** `xlsx` Package, Spalte "EP netto" = VK-Preis
2. **Artikelnummer-Mapping:** Excel `01.01.2` ‚Üí Supabase `GWS.LV23-01.01.2`
3. **Vergleich erstellen:** `scripts/compare_gws_prices_full.js`
4. **Supabase aktualisieren:** UPDATE lv_positionen SET listenpreis = [EXCEL_PREIS]
5. **Hero pr√ºfen:** Manuell in Hero Software aktualisieren
**Dateien:**
- `docs/gws_price_comparison.json` - Vergleichsergebnis
- `docs/hero_gws_price_comparison.json` - Hero-Diskrepanzen
**Wichtig:** Preishistorie-Trigger protokolliert automatisch (L168)

### L165 - Logo-Pfad f√ºr PDF-Generierung zentral in docs/
**Datum:** 2026-02-01
**Kontext:** PDF-Generierung mit Puppeteer braucht Bilder
**L√∂sung:** Logo und andere Assets in `docs/` Ordner kopieren
**Pfade:**
- `docs/logo-neurealis.png` - neurealis Logo f√ºr alle PDFs
- Quelle: `ui/static/logo-neurealis.png`
**Verwendung im HTML:**
- Relativer Pfad: `src="logo-neurealis.png"` (wenn HTML in docs/)
- Puppeteer PDF: `page.goto('file:///.../docs/DOCUMENT.html')`
**Vorteil:** Ein Ort f√ºr alle PDF-Assets, konsistente CI

### L166 - PFLICHT: Hilfe-Dokumentation bei Feature-√Ñnderungen aktualisieren
**Datum:** 2026-02-01
**Kontext:** User Guide f√ºr Telegram-Bot muss aktuell bleiben
**Regel:** Bei JEDER √Ñnderung am Telegram-Bot oder ERP-Features:
1. `docs/TELEGRAM_BOT_USER_GUIDE.html` aktualisieren
2. PDF neu generieren mit Puppeteer
3. Nach `ui/static/docs/` kopieren f√ºr Web-Zugriff
4. Commit mit "docs:" Pr√§fix
**Hilfe-Seite:** `/hilfe` im ERP (f√ºr alle Rollen sichtbar)
**Grund:** Bauleiter brauchen aktuelle Anleitungen, veraltete Doku = Support-Aufwand

### L163 - Microsoft Graph API Rate-Limiting (429)
**Datum:** 2026-02-01
**Kontext:** SharePoint-Sync mit vielen parallelen Downloads
**Problem:** Graph API gibt 429 (activityLimitReached, throttledRequest, quota) bei zu vielen Requests
**L√∂sung:**
1. Sequentielle Verarbeitung statt parallel (ITEM_CONCURRENCY = 1)
2. Delay zwischen Downloads (500ms)
3. Retry mit Exponential Backoff (max 3 Versuche)
4. `Retry-After` Header auslesen und warten
**Wichtig:** Bei gro√üen Sync-Jobs Sites einzeln verarbeiten, nicht alle auf einmal

### L164 - SharePoint Delta-Query bei Full-Sync
**Datum:** 2026-02-01
**Kontext:** Initial-Sync f√ºr SharePoint Sites
**Verhalten:**
- Erster Sync OHNE delta_link ‚Üí Alle Dateien (Full-Sync)
- Folge-Syncs MIT delta_link ‚Üí Nur neue/ge√§nderte Dateien
- `items_synced: 0` ist NORMAL nach initialem Sync wenn keine √Ñnderungen
**Tipp:** F√ºr Full-Sync: `delta_link = NULL` setzen vor Sync-Aufruf

### L148 - Telegram-Bot Men√º: ATBS-Schnellzugriff nach Favoriten
**Datum:** 2026-02-01
**Kontext:** Hauptmen√º-Reihenfolge f√ºr Bauleiter optimiert
**Beste Reihenfolge:**
1. ‚≠ê Favoriten (Top 3 Projekte)
2. üîç ATBS direkt eingeben (schnellster Weg)
3. üèóÔ∏è Baustelle √∂ffnen (Phasen-Filter)
4. üìä Aufma√ü erstellen
5. üéôÔ∏è Audio-Briefing (nur Bauleiter)
6. üìù Bedarfsanalyse (ans Ende, selten genutzt)
**Grund:** Bauleiter kennt meist die ATBS-Nummer, braucht schnellen Zugriff

### L147 - Learnings Summary f√ºr Preflight (PFLICHT!)
**Datum:** 2026-02-01
**Problem:** `learnings.md` mit 160+ Eintr√§gen √ºberschreitet 25k Token-Limit
**L√∂sung:** `learnings_summary.md` als kompakter Index (Tabellen mit Titel + 1-Zeiler)
**Workflow:**
1. Preflight liest `learnings_summary.md` (schnell, kompakt)
2. Bei Bedarf Volltext `learnings.md` mit offset/limit lesen
3. Neue Learnings IMMER in beiden Dateien erg√§nzen!
**Vorteil:** Kein Wissensverlust, schnellerer Preflight, alle Learnings zug√§nglich

### L143 - Audio-Generierung NUR auf Edge Functions
**Datum:** 2026-02-01
**Regel:** Audio-Briefings werden AUSSCHLIESSLICH √ºber Supabase Edge Functions generiert, NIEMALS lokal.
**Grund:** OpenAI API Key ist in Supabase Secrets, nicht lokal verf√ºgbar.

### L144 - Pr√§fix-Konvention in monday_bauprozess (WICHTIG!)
**Datum:** 2026-02-01
**Kontext:** Eindeutige Spaltennamen mit Pr√§fixen f√ºr NU, BL, AG

#### NU (Nachunternehmer) Felder:
| Monday-Spalte | Supabase-Spalte | Beschreibung |
|---------------|-----------------|--------------|
| Nachunternehmer | `nu_firma` | NU Firmenname (z.B. "TOP Handwerker") |
| Ansprechpartner \| Nachunternehmer (NU) | `nu_ansprechpartner` | NU Ansprechpartner-Name |
| Telefon \| Nachunternehmer (NU) | `nu_telefon` | NU Handynummer |
| E-Mail \| Nachunternehmer (NU) | `nu_email` | NU E-Mail |

#### BL (Bauleiter) Felder:
| Supabase-Spalte | Beschreibung |
|-----------------|--------------|
| `bl_name` | Bauleiter Name |
| `bl_email` | Bauleiter E-Mail |
| `bl_telefon` | Bauleiter Telefon |

#### AG (Auftraggeber/Kunde) Felder:
| Supabase-Spalte | Beschreibung |
|-----------------|--------------|
| `ag_name` | Kundenname |
| `ag_nummer` | Kundennummer |
| `ag_email` | Kunden E-Mail |
| `ag_telefon` | Kunden Telefon |

**Verwendung im Telegram Bot:**
```
üîß NU: [nu_firma] - [nu_ansprechpartner] ([nu_telefon])
```

**MERKE:** Bei NU-Anzeige IMMER nu_* Felder nutzen, nicht aus kontakte-Tabelle holen!

### L145 - DB-Spalten mit Pr√§fixen f√ºr Eindeutigkeit
**Datum:** 2026-02-01
**Regel:** Spalten die zu verschiedenen Entit√§ten geh√∂ren mit Pr√§fix benennen.
**Beispiel:**
- `nu_firma`, `nu_email` (Nachunternehmer)
- `bl_name`, `bl_email` (Bauleiter)
- `ag_name`, `ag_email` (Auftraggeber)
**Vorteil:** Keine Verwechslung, eindeutige Queries, bessere Autovervollst√§ndigung
**Ausnahme:** Projekt-Stammdaten ohne Pr√§fix (atbs_nummer, budget, baustart)

### L146 - Edge Functions: verify_jwt f√ºr Cron-Jobs
**Datum:** 2026-02-01
**Problem:** Edge Functions mit `verify_jwt: true` k√∂nnen nicht von pg_net/Cron aufgerufen werden (401 Missing authorization header)
**L√∂sung:** F√ºr Cron-basierte Functions `verify_jwt: false` setzen
**Regel:**
- `verify_jwt: true` ‚Üí Nur f√ºr User-aufgerufene Functions (mit Auth-Token)
- `verify_jwt: false` ‚Üí F√ºr Cron-Jobs, DB-Trigger, interne Calls
**Beispiel:** `monday-sync` muss `verify_jwt: false` haben da es vom Cron-Job aufgerufen wird

---

## UX/Design

### L001 - Softr Tab-√úberladung vermeiden
**Datum:** 2026-01-27
**Problem:** Das interne Softr-Portal hat 20+ Tabs pro Bauvorhaben ‚Üí kognitive √úberlastung
**L√∂sung:** Progressive Disclosure, Accordion-Pattern, nur relevante Infos je nach Phase zeigen

### L002 - Horizontales Scrollen ist Gift
**Datum:** 2026-01-27
**Problem:** Tabellen mit 15+ Spalten sind auf Mobile unbrauchbar
**L√∂sung:** Spalten-Konfigurator, wichtige Spalten fixieren, Card-Layout f√ºr Mobile

### L003 - Redundanz eliminieren
**Datum:** 2026-01-27
**Problem:** Gleiche Infos in mehreren Tabs f√ºhren zu Inkonsistenzen
**L√∂sung:** Single Source of Truth, nur an einer Stelle editierbar

---

## Technisch

### L004 - Supabase MCP direkt nutzen
**Datum:** 2026-01-26
**Problem:** Manuelle SQL-Migrations sind fehleranf√§llig
**L√∂sung:** `mcp__supabase__apply_migration` f√ºr DDL, `mcp__supabase__execute_sql` f√ºr Queries

### L005 - gpt-5.2 nicht gpt-5.2-mini
**Datum:** 2026-01-26
**Problem:** GPT-5.2-mini hat schlechtere Ergebnisse beim Parsen
**L√∂sung:** Immer gpt-5.2 (Hauptmodell) verwenden

### L006 - Umlaute korrekt verwenden
**Datum:** 2026-01-26
**Problem:** ae/oe/ue sieht unprofessionell aus
**L√∂sung:** UTF-8 √ºberall, deutsche Umlaute (√§, √∂, √º, √ü) verwenden

---

## Workflow

### L007 - Edge Functions in functions/supabase/functions/
**Datum:** 2026-01-26
**Problem:** Verschiedene Pfade f√ºr Functions
**L√∂sung:** Alle Edge Functions unter `functions/supabase/functions/`

### L008 - Parallele Subagenten f√ºr schnelle UI-Entwicklung
**Datum:** 2026-01-27
**Problem:** Sequentielle Seitenentwicklung ist langsam
**L√∂sung:** Task-Tool mit mehreren parallelen Subagenten (bis zu 6 gleichzeitig)
**Ergebnis:** 11 Seiten in ~30 Minuten statt mehreren Stunden

### L009 - Svelte 5 Snippet-Namen ohne Bindestriche
**Datum:** 2026-01-27
**Problem:** `{#snippet user-info()}` verursacht Syntax-Fehler
**L√∂sung:** Keine Bindestriche in Snippet-Namen, oder Props statt Snippets verwenden

### L010 - Windows-Pfade in Bash problematisch
**Datum:** 2026-01-27
**Problem:** `cd C:\Users\...` funktioniert nicht in Bash-Umgebung
**L√∂sung:** Dev-Server manuell in PowerShell starten: `cd ui && npm run dev`

---

## Hero API

### L011 - Hero invoice_style f√ºr Teil/Schlussrechnungen
**Datum:** 2026-01-27
**Problem:** Bisherige Fallback-Logik (Projekt-Phase, h√∂chste RE-Nr) war unzuverl√§ssig
**L√∂sung:** `metadata.invoice_style` direkt aus Hero API nutzen:
- `full` ‚Üí AR-S (Schlussrechnung)
- `parted`/`cumulative`/`downpayment` ‚Üí AR-A (Abschlag)
- `null` ‚Üí Ignorieren (Entwurf)
**Doku:** `docs/HERO_RECHNUNGSSYNC_API.md`

### L012 - Hero Schlussrechnung = Restbetrag
**Datum:** 2026-01-27
**Problem:** Annahme dass Schlussrechnung Gesamtbetrag enth√§lt
**Wahrheit:** Bei vorherigen Teilrechnungen enth√§lt die Schlussrechnung nur den **Differenzbetrag**
**Beispiel:** Projekt mit 2 Teilrechnungen (4.500‚Ç¨ + 5.000‚Ç¨) hat Schlussrechnung von nur 8.900‚Ç¨ (Rest)

---

## Business / Wohnungssanierung

### L013 - Leerstandskosten als Verhandlungsargument
**Datum:** 2026-01-27
**Kontext:** VBW-Preisverhandlung LV 2026
**Erkenntnis:** Leerstandskosten sind ein starkes Argument f√ºr Prozessoptimierung
**Formel:** `Wohnungen/Jahr √ó Verz√∂gerungswochen √ó √ò-Fl√§che √ó ‚Ç¨/m¬≤/Monat √∑ 4`
**Beispiel VBW:** 280 WE √ó 3 Wochen √ó 60m¬≤ √ó 8,50‚Ç¨ √∑ 4 = **357.000‚Ç¨/Jahr**

### L014 - Ausrei√üer-Analyse f√ºr LV-Verhandlungen
**Datum:** 2026-01-27
**Kontext:** VBW LV 2026 vs. GWS-Marktpreise
**Methode:**
1. Altes LV (2023) gegen neues LV (2026) vergleichen
2. Referenz-BVs als Praxistest (verschiedene Gr√∂√üen)
3. Markt-LV (z.B. GWS) als externe Benchmark
4. Ausrei√üer sortiert nach Abweichung pr√§sentieren
**Kritische Schwellen:** >25% Abweichung = Gespr√§chsbedarf

### L015 - Materialvorschl√§ge dokumentieren
**Datum:** 2026-01-27
**Erkenntnis:** Bei LV-Verhandlungen immer konkrete Alternativen nennen
**Wichtige Kriterien:**
- Verf√ºgbarkeit (Lieferzeiten)
- EK-Preis
- Qualit√§t (z.B. DK02 nicht rutschhemmend ‚Üí Kermos)
- Markenakzeptanz beim Auftraggeber

### L016 - Prozessoptimierung bei Wohnungssanierung
**Datum:** 2026-01-27
**Problem:** 3 Wochen Verz√∂gerung zwischen Auszug und Baustart
**Ursache:** BL-Zuweisung erst nach Auszug, dann erst Begehung/Budget
**L√∂sung:**
- BL direkt bei K√ºndigung zuweisen (nach Stra√üen/Regionen)
- Erstbegehung 1-2 Wochen nach K√ºndigung (bewohnte Wohnung)
- Budget-Freigabe vor Auszug
- Direkter Baustart nach Auszug
**Risiko:** M√§ngel bei Begehung nicht sichtbar ‚Üí Nachtr√§ge einplanen

### L017 - VBW Zahlungsziel-Argumentation
**Datum:** 2026-01-27
**Ziel:** 14 Tage netto beibehalten (statt 30 netto / 14-3%)
**Argumente:**
- NUs sind kleine Betriebe, brauchen schnelle Zahlung
- Gute NUs durch p√ºnktliche Zahlung halten
- Vorleistung bei Material (Lagerware) erm√∂glicht bessere EK-Konditionen
- Funktionierendes System nicht √§ndern
**Red Line:** Maximal 21 Tage netto ohne Skonto

### L018 - VBW LV 2026 - Kritische Positionen
**Datum:** 2026-01-27
**Top-Ausrei√üer (Unterdeckung):**
| Pos. | Position | Abweichung | Mindestpreis |
|------|----------|------------|--------------|
| 3.3 | K√ºchenstr√§nge | -72% | 800‚Ç¨ |
| 1.5 | Elektroschlitze | -54% | - |
| 2.1 | E-Anlage | -44% | 3.800‚Ç¨ |
| 6.3 | Vinyl-Boden | -40% | 28‚Ç¨/m¬≤ |
| 7.2 | WE-T√ºr | -25% | 1.260‚Ç¨ |

### L019 - VBW Material-Freigaben
**Datum:** 2026-01-27
**Genehmigte Alternativen:**
| Position | Aktuell | Vorschlag | Vorteil |
|----------|---------|-----------|---------|
| Schalter | Gira E2 | Gira Standard 55 | G√ºnstiger, gleiche Qualit√§t |
| Badl√ºfter | Ritzer Limodor | Maico ECA 100 ipro K | Nachlauf, Verf√ºgbarkeit |
| Sanit√§r | diverse | Vigour One | Preis-Leistung |
| Fliesen | DK02 | Kermos 8mm | Rutschhemmend! |
| Sockelleisten | Holz | KSO Kunststoff | G√ºnstiger |
| Innent√ºren | Jeld-Wen | Pr√ºm R√∂hrenspahn | Kostenoptimiert |
| WE-T√ºr | Jeld-Wen | Pr√ºm KK2 RC2 | - |
| Beschl√§ge | Griffwerk | Becher/Hoppe Amsterdam | Preis |

---

## Deployment

### L020 - Svelte 5 @const Placement
**Datum:** 2026-01-28
**Problem:** `{@const}` direkt in `<div>` verursacht Build-Fehler
**L√∂sung:** `{@const}` muss innerhalb von `{#if}`, `{#each}`, `{:else}`, etc. sein
**Beispiel:**
```svelte
<!-- FALSCH -->
<div>
  {@const wert = berechnung()}
  {wert}
</div>

<!-- RICHTIG -->
{#if true}
  {@const wert = berechnung()}
  <div>{wert}</div>
{/if}
```

### L021 - Netlify adapter-netlify: Edge Functions bevorzugen
**Datum:** 2026-01-28
**Problem:** 404 nach Deploy trotz korrekter Functions
**Ursache:** Regular Functions (`edge: false`) funktionierten nicht zuverl√§ssig
**L√∂sung:** `edge: true` in svelte.config.js verwenden
```javascript
adapter: adapter({
  edge: true,  // <- wichtig!
  split: false
})
```
**Vorteil:** Edge Functions sind schneller und zuverl√§ssiger

---

## Supabase Storage

### L022 - Dateinamen f√ºr Storage sanitizen
**Datum:** 2026-01-28
**Problem:** Upload schl√§gt fehl mit "Invalid key" bei Umlauten/Leerzeichen
**L√∂sung:** Dateinamen vor Upload bereinigen:
```javascript
filename
  .replace(/√§/g, 'ae').replace(/√∂/g, 'oe').replace(/√º/g, 'ue')
  .replace(/\s+/g, '_')
  .replace(/[^a-zA-Z0-9_.-]/g, '');
```

### L023 - Edge Functions f√ºr Batch-Prozesse
**Datum:** 2026-01-28
**Problem:** Lokale Scripts brauchen Service Role Key, der abl√§uft
**L√∂sung:** Edge Functions nutzen - haben automatisch Zugriff auf `SUPABASE_SERVICE_ROLE_KEY`
**Vorteil:** Keine lokalen Credentials, als Cron-Job nutzbar

---

## Claude Code / Subagenten

### L024 - Subagenten vs. Batch-Scripts
**Datum:** 2026-01-28
**Problem:** Subagenten f√ºr Datei-Operationen sind ineffizient (1 Tool-Call pro Datei)
**L√∂sung:** Bei Batch-Operationen (z.B. 600+ PDFs):
1. Ein Script/Edge Function schreiben
2. Parallel processing im Script (nicht parallel Subagenten)
**Beispiel:** 642 PDFs in 80s statt gesch√§tzt 30+ Minuten mit Subagenten

---

### L025 - Unified Documents Table f√ºr RAG
**Datum:** 2026-01-28
**Problem:** Zwei separate Dokumenten-Tabellen (softr_dokumente, dokumente) erschweren RAG-Integration
**L√∂sung:** Eine `dokumente` Tabelle mit allen Feldern:
- `is_native_pdf` - Klassifizierung f√ºr OCR-Entscheidung
- `raw_text` - Extrahierter Text
- `summary` - KI-generierte Zusammenfassung
- `embedding` - vector(1536) f√ºr Similarity-Search
**Ergebnis:** Single Source of Truth f√ºr alle Dokumente

### L026 - OpenAI Batch API f√ºr Kostenersparnis
**Datum:** 2026-01-28
**Problem:** Einzelne API-Calls f√ºr 1.800+ Dokumente sind teuer
**L√∂sung:** OpenAI Batch API nutzen (50% g√ºnstiger)
- JSONL-Format f√ºr Batch-Requests
- Asynchrone Verarbeitung (bis 24h)
- Ergebnisse als JSONL abrufbar
**Implementierung:** Edge Function `document-batch` mit modes: create, status, process

### L027 - S3 Signed URLs verfallen
**Datum:** 2026-01-28
**Problem:** Softr S3-URLs haben `X-Amz-Expires=3600` (1 Stunde)
**Auswirkung:** 447 Dokumente mit abgelaufenen URLs
**L√∂sung:** PDFs zu Supabase Storage kopieren mit permanenten public URLs
**Edge Function:** `hero-pdf-sync` bereits vorhanden

---

## Claude Code / Effizienz

### L029 - Subagenten f√ºr Recherche (Kontext-Schonung)
**Datum:** 2026-01-28
**Problem:** Recherche (API-Doku, Produkte, Codebase) f√ºllt Kontext-Window mit Suchprozess
**L√∂sung:** Task-Tool mit Explore-Subagent nutzen
- Subagent hat eigenes Kontext-Window
- Nur kompakte Antwort kommt zur√ºck
- Bei mehreren Fragen: Parallele Subagenten
**Regel:** In globaler CLAUDE.md v2.2 dokumentiert - gilt projekt√ºbergreifend

---

## OpenAI API

### L028 - GPT-5.2 verwendet max_completion_tokens
**Datum:** 2026-01-28
**Problem:** API-Fehler 400: "Unsupported parameter: 'max_tokens' is not supported with this model"
**L√∂sung:** Bei GPT-5.2 `max_completion_tokens` statt `max_tokens` verwenden
```javascript
// FALSCH f√ºr GPT-5.2
{ model: 'gpt-5.2', max_tokens: 200 }

// RICHTIG f√ºr GPT-5.2
{ model: 'gpt-5.2', max_completion_tokens: 200 }
```
**Hinweis:** √Ñltere Modelle (gpt-4o, gpt-3.5) nutzen weiterhin `max_tokens`

---

## Hero API

### L030 - Hero hat keine Webhook-API
**Datum:** 2026-01-28
**Problem:** Annahme dass Make.com "Watch Documents" echte Webhooks nutzt
**Wahrheit:** Hero Software bietet **keine native Webhook-Funktionalit√§t**
- GraphQL API v7 hat nur Queries/Mutations, keine Subscriptions
- Make.com Integration basiert auf **Polling** (periodisches Abfragen)
- Alle Partner-Integrationen (DAA, Leveto, ContactsforHERO) sind spezifische Anbindungen
**Konsequenz:** Cron-Job ist die richtige L√∂sung, kein Umstellungs-Vorteil
**Quellen:**
- https://hero-software.de/api-doku/graphql-guide
- https://hero-software.de/features/schnittstellen

---

## Monday.com Integration

### L031 - Monday Bidirektional Sync
**Datum:** 2026-01-28
**Problem:** monday-sync pullt nur von Monday, aber pusht nicht zur√ºck
**L√∂sung:** Separate `monday-push` Edge Function erstellen
**Workflow:**
1. Supabase-Daten aktualisieren
2. `sync_status = 'pending_push'` setzen
3. monday-push Function triggern
**Feld-Mapping (JSONB column_values):**
- `zahlen1__1` = Projektvolumen netto
- `zahlen77__1` = Projektvolumen brutto
- `numeric65__1` = NU-Budget netto
- `text23__1` = NUA-Nr
- `text49__1` = ATBS-Nr

### L032 - NUA-Budget-Berechnung
**Datum:** 2026-01-28
**Kontext:** VBW-Projekte brauchen automatische NUA-Budget-Berechnung
**Formel:** `NUA_Netto = SUM(AB_Netto) * 0.75`
**Rohertrag:** 25% Marge (standardm√§√üig)
**Zuordnung:** √úber ATBS-Nummer (bv_id in dokumente)

---

## Supabase

### L033 - Upsert ben√∂tigt Unique Constraint
**Datum:** 2026-01-28
**Problem:** Supabase upsert mit onConflict schl√§gt fehl ohne Constraint
**Fehler:** `there is no unique or exclusion constraint matching the ON CONFLICT specification`
**L√∂sung:** Unique Constraint vor Upsert erstellen:
```sql
ALTER TABLE dokumente ADD CONSTRAINT dokumente_dokument_nr_unique UNIQUE (dokument_nr);
```

### L034 - Default UUID f√ºr NOT NULL Spalten
**Datum:** 2026-01-28
**Problem:** Insert schl√§gt fehl mit "null value in column 'id' violates not-null constraint"
**L√∂sung:** Default-Wert setzen:
```sql
ALTER TABLE dokumente ALTER COLUMN id SET DEFAULT gen_random_uuid()::text;
```

### L035 - UNIQUE Constraint mit NULL-Werten
**Datum:** 2026-01-28
**Problem:** UNIQUE(a, b) erlaubt mehrere Zeilen wenn b NULL ist (PostgreSQL NULL-Semantik)
**Kontext:** email_details mit UNIQUE(message_id, account_email) - Anh√§nge haben gleiche message_id
**L√∂sung:** COALESCE in Index verwenden:
```sql
CREATE UNIQUE INDEX email_details_unique_idx
  ON email_details (message_id, account_email, COALESCE(attachment_id, ''));
```
**Grund:** COALESCE wandelt NULL in leeren String um, macht Vergleich deterministisch

### L036 - Graph API Attachments: contentBytes einzeln abrufen
**Datum:** 2026-01-28
**Problem:** GET /messages/{id}/attachments liefert KEINE contentBytes (Base64-Inhalt)
**L√∂sung:** Zwei-Schritt-Verfahren:
1. Liste abrufen: `/attachments?$select=id,name,contentType,size,isInline`
2. Pro Anhang einzeln: `/attachments/{att.id}` ‚Üí enth√§lt contentBytes

### L037 - Supabase Storage: Pfad-Sanitization f√ºr Message-IDs
**Datum:** 2026-01-28
**Problem:** internetMessageId enth√§lt `<xxx@yyy.com>` - Sonderzeichen verursachen 400-Fehler
**Fehler:** Storage-Pfade wie `/2026/%3Cxxx/...` (URL-encoded `<`)
**L√∂sung:** Sonderzeichen entfernen:
```typescript
const safeMessageId = emailMessageId.replace(/[<>@.]/g, '').substring(0, 12);
```

---

## E-Mail Integration

### L038 - E-Mail-Import Architektur
**Datum:** 2026-01-28
**Kontext:** MS365 Graph API ‚Üí Supabase Integration
**Architektur:**
- `email-fetch`: Holt E-Mails, speichert Anh√§nge in Storage, erstellt dokumente + email_details
- `email-process`: Matching-Kaskade (Domain ‚Üí ATBS-Pattern ‚Üí Postfach ‚Üí Kontakt-Anlage)
**Tabellen:**
- `dokumente`: E-MAIL (E-Mails), E-ANH (Anh√§nge)
- `email_details`: E-Mail-spezifische Metadaten, verkn√ºpft mit dokumente
- `kontakt_domains`: Domain ‚Üí Kontakt Mapping f√ºr Auto-Zuordnung
**Cron:** email-fetch alle 10 Min, email-process alle 15 Min (versetzt)

---

## Hero API (Fortsetzung)

### L039 - Hero GraphQL: temporary_url explizit abfragen
**Datum:** 2026-01-28
**Problem:** PDF-Download schl√§gt fehl obwohl Dokumente in Hero existieren
**Ursache:** GraphQL Query hatte nur `file_upload { filename }` ohne `temporary_url`
**L√∂sung:** Immer alle ben√∂tigten Felder explizit abfragen:
```graphql
file_upload {
  filename
  temporary_url  # <- MUSS dabei sein f√ºr Downloads!
}
```
**Konsequenz:** OTC-URLs (temporary_url) verfallen nach kurzer Zeit, sofort nach Abruf verarbeiten

### L040 - Supabase Storage: Umlaute in Dateinamen
**Datum:** 2026-01-28
**Problem:** Upload schl√§gt fehl: "Invalid key: hero-docs/Auftragsbest√§tigung-..."
**Ursache:** Supabase Storage akzeptiert keine Umlaute oder Sonderzeichen im Pfad
**L√∂sung:** Filename-Sanitization vor Upload:
```javascript
function sanitizeFilename(filename) {
  return filename
    .replace(/√§/g, 'ae').replace(/√Ñ/g, 'Ae')
    .replace(/√∂/g, 'oe').replace(/√ñ/g, 'Oe')
    .replace(/√º/g, 'ue').replace(/√ú/g, 'Ue')
    .replace(/√ü/g, 'ss')
    .replace(/[^a-zA-Z0-9._-]/g, '_')
    .replace(/_+/g, '_');
}
```
**Hinweis:** Gilt f√ºr alle Storage-Operationen, nicht nur Hero-Sync

---

---

## Daten-Sync

### L041 - Upsert √ºberschreibt existierende Werte mit NULL/0
**Datum:** 2026-01-28
**Problem:** `hero-document-sync` √ºberschrieb existierende Netto/Brutto-Werte mit 0
**Ursache:** Code `const netto = doc.value || 0;` setzt 0 wenn Hero keinen Wert hat
**L√∂sung:** Felder nur ins Record aufnehmen wenn Quelle tats√§chlich Werte hat:
```javascript
// FALSCH: √úberschreibt immer
const record = {
  betrag_netto: doc.value || 0,  // 0 bei fehlendem Wert!
  ...
};

// RICHTIG: Nur setzen wenn vorhanden
const record = { ... };
if (doc.value !== null && doc.value !== 0) {
  record.betrag_netto = doc.value;
}
```
**Konsequenz:** 11 Dokumente mussten aus Softr-Backup wiederhergestellt werden
**Regel:** Bei Upsert pr√ºfen ob Source-Wert existiert bevor Feld ins Record kommt

---

## Supabase Client / PostgREST

### L042 - Supabase Client JSONB-Filter funktionieren nicht zuverl√§ssig
**Datum:** 2026-01-28
**Problem:** `.filter('column_values', 'cs', '{"text49__1":...}')` verursacht JSON-Parse-Fehler
**Fehler:** `invalid input syntax for type json`
**Ursache:** Supabase Client √ºbersetzt `cs` (contains) nicht korrekt f√ºr JSONB-Spalten
**L√∂sung:** Alle Datens√§tze laden und in JavaScript filtern:
```javascript
// FALSCH: Supabase client filter auf JSONB
const { data } = await supabase
  .from('monday_bauprozess')
  .select('*')
  .filter('column_values', 'cs', JSON.stringify({text49__1: 'ATBS-445'}));

// RICHTIG: Alle laden und manuell filtern
const { data } = await supabase.from('monday_bauprozess').select('*');
const match = data.find(p => extractText(p.column_values?.['text49__1']) === 'ATBS-445');
```
**Alternative:** Raw SQL mit `@>` Operator oder RPC-Function nutzen

### L043 - Edge Functions: verify_jwt f√ºr interne Calls
**Datum:** 2026-01-28
**Problem:** Edge Function A ruft Edge Function B auf ‚Üí 401 Invalid JWT
**Ursache:** Edge Function B hat `verify_jwt: true` und erwartet User-JWT
**L√∂sung:** Zwei Optionen:
1. **verify_jwt: false** - F√ºr interne Functions die nur von anderen Functions aufgerufen werden
2. **Service Role Key** - Authorization Header mit Service Role Key forwarden
```javascript
// Edge Function B mit verify_jwt: false deployen:
await mcp__supabase__deploy_edge_function({
  name: 'email-send',
  verify_jwt: false,  // <- Erlaubt Calls ohne User-JWT
  ...
});
```
**Regel:** verify_jwt: true nur f√ºr User-facing Endpoints, false f√ºr interne Calls

### L044 - PostgREST LIKE-Pattern: %25 statt *
**Datum:** 2026-01-28
**Problem:** REST API Abfrage mit `like.ER-NU-S*` findet keine Ergebnisse
**Ursache:** PostgREST nutzt SQL LIKE-Syntax mit `%`, nicht `*`
**L√∂sung:** `%` URL-encoded als `%25` verwenden:
```javascript
// FALSCH
const url = `${supabaseUrl}/rest/v1/dokumente?art_des_dokuments=like.ER-NU-S*`;

// RICHTIG
const url = `${supabaseUrl}/rest/v1/dokumente?art_des_dokuments=like.ER-NU-S%25`;
```
**Hinweis:** Bei Supabase Client funktioniert `.like('art', 'ER-NU-S%')` korrekt

---

### L045 - PFLICHT: Backup vor DB-√Ñnderungen mit KI
**Datum:** 2026-01-28 (erweitert 2026-01-29)
**Kontext:** Datenwiederherstellung nach hero-document-sync Bug
**REGEL (MUST-HAVE):** Vor JEDER direkten DB-√Ñnderung mit Claude MUSS ein Backup erstellt werden:
1. **Query vorher ausf√ºhren:** `SELECT * FROM tabelle WHERE bedingung` ‚Üí JSON exportieren
2. **Backup speichern:** `docs/backups/[datum]_[tabelle]_[aktion].json`
3. **√Ñnderungsprotokoll in Backup-Datei:**
   ```json
   {
     "datum": "2026-01-29",
     "tabelle": "maengel_fertigstellung",
     "aktion": "UPDATE status_mangel",
     "where_clause": "WHERE id IN ('uuid1', 'uuid2')",
     "betroffene_records": 5,
     "rollback_query": "UPDATE maengel_fertigstellung SET status_mangel = 'Offen' WHERE id IN (...)",
     "backup_data": [...]
   }
   ```
4. **Erst dann:** UPDATE/DELETE/INSERT ausf√ºhren
5. **Verifizieren:** Nach √Ñnderung kurzer SELECT um Erfolg zu pr√ºfen

**Backup-Verzeichnis:** `docs/backups/` f√ºr alle Daten-Snapshots vor √Ñnderungen
**Beispiel:** `docs/softr_amounts_backup.json` rettete 11 Dokumente (~142.578 ‚Ç¨)
**Grund:** KI kann Fehler machen - Backups mit vollst√§ndigem Protokoll erm√∂glichen IMMER exakten Rollback

---

## Marketing / Blog-Pipeline

### L046 - OpenAI Responses API mit web_search_preview
**Datum:** 2026-01-28
**Kontext:** Blog-Pipeline ben√∂tigt Web-Recherche f√ºr aktuelle Trends
**L√∂sung:** OpenAI Responses API mit `web_search_preview` Tool:
```typescript
const response = await fetch('https://api.openai.com/v1/responses', {
  method: 'POST',
  headers: { 'Authorization': `Bearer ${OPENAI_API_KEY}` },
  body: JSON.stringify({
    model: 'gpt-5.2',
    input: 'Aktuelle KfW-F√∂rderungen 2026',
    tools: [{ type: 'web_search_preview' }]
  })
});
```
**Hinweis:** Responses API ist der neue Standard f√ºr Agenten-Funktionalit√§t bei OpenAI

### L047 - Agenten-Kommunikation via JSON-Output
**Datum:** 2026-01-28
**Kontext:** Blog-Pipeline mit 3 Agenten (Editor ‚Üí Recherche ‚Üí Writer)
**Pattern:** Jeder Agent gibt strukturiertes JSON aus, das der n√§chste als Input erh√§lt
**Vorteil:** Klar definierte Schnittstellen, einfaches Debugging, keine Tool-Calls zwischen Agenten n√∂tig
**Implementierung:** Edge Function als Orchestrator koordiniert die Aufrufe sequentiell

### L048 - Embedding-basierte Querverlinkung f√ºr SEO
**Datum:** 2026-01-28
**Kontext:** Blog-Artikel sollen sich gegenseitig verlinken (SEO: Domain Rating)
**L√∂sung:**
1. Jeder Artikel erh√§lt vector(1536) Embedding bei Erstellung
2. RPC `search_similar_blog_posts()` findet √§hnliche Artikel
3. Writer-Agent erh√§lt Top-5 √§hnliche Posts als Verlinkungsvorschl√§ge
4. W√∂chentlicher Cron pr√ºft alle Artikel auf fehlende Verlinkung
**Regel:** Minimum 2 interne Links pro Artikel

---

## Claude Code / Subagenten (Fortsetzung)

### L049 - Explore-Subagent und lokale Dateien (KORRIGIERT)
**Datum:** 2026-01-28 (korrigiert 2026-01-29)
**Urspr√ºngliche Annahme (FALSCH):** Subagenten k√∂nnen keine lokalen Dateien lesen
**RICHTIG:** Subagenten K√ñNNEN lokal synchronisierte Dateien lesen (z.B. OneDrive-Ordner)
**Problem nur bei:** Unsynchronisierte Cloud-Dateien (Datei nur in der Cloud, nicht lokal)
**Fazit:** Bei synchronisierten OneDrive/SharePoint-Ordnern funktionieren Subagenten f√ºr PDFs

### L050 - Wissens-Struktur f√ºr Blog-Pipeline
**Datum:** 2026-01-28
**Kontext:** Extrahiertes Wissen aus internen Dokumenten f√ºr Content-Marketing
**L√∂sung:** `wissen/` Ordner mit thematischen Markdown-Dateien:
- `vertrieb_prozesse.md` - Sales-Ablauf, USPs, Kennzahlen
- `marketing_strategie.md` - Positionierung, Content-Cluster
- `README.md` - Index der Wissensdateien
**Nutzung:**
1. Blog-Pipeline liest relevante Wissensdateien als System-Prompt
2. Agenten haben Zugriff auf aktuelle Unternehmens-Infos
3. Einheitliche Terminologie und Zahlen √ºber alle Artikel

---

## Bauprozess / Gewerke

### L051 - Monday Ausf√ºhrungsarten und Nachweis-Anforderungen
**Datum:** 2026-01-28
**Kontext:** Automatische Nachweis-E-Mails bei NU-Schlussrechnungen

**Relevante Monday-Spalten f√ºr Ausf√ºhrungsart:**

| Spalte | Gewerk | M√∂gliche Werte |
|--------|--------|----------------|
| `color590__1` | Elektrik | Komplett, Teil-Mod, Austausch Feininstallation, Nur E-Check, Ohne |
| `status23__1` | Bad | Komplett, Fliese auf Fliese, Nur Austausch Sanit√§rartikel, Ohne Bad |
| `color78__1` | Boden | Ohne, Vinyl (Planken), Ausgleich, Laminat, Vinyl (Click), Holz schleifen, Fliesen |
| `color427__1` | W√§nde | Ohne, Raufaser & Anstrich, 2x Anstrich, Q2 & Anstrich, Nur Spachteln |
| `color97__1` | T√ºren | Ohne, T√ºrbl√§tter: neu \| Zarge: neu, lackieren \| lackieren, neu \| lackieren |
| `color49__1` | Therme | Ohne Therme, Therme versetzen, Neue Therme, Asbestsanierung |

**Nachweis-Logik nach Ausf√ºhrungsart:**

**Elektrik (color590__1):**
| Ausf√ºhrung | Rohinstallation Elektrik | E-Check |
|------------|-------------------------|---------|
| Komplett | ‚úÖ | ‚úÖ |
| Teil-Mod (UV + Schalter) | ‚ùå | ‚úÖ |
| Austausch Feininstallation | ‚ùå | ‚úÖ |
| Nur E-Check | ‚ùå | ‚úÖ |
| Ohne | ‚ùå | ‚ùå |

**Bad (status23__1):**
| Ausf√ºhrung | Rohinstallation Sanit√§r | Abdichtung Bad |
|------------|------------------------|----------------|
| Komplett | ‚úÖ | ‚úÖ |
| Fliese auf Fliese | ‚ùå | ‚úÖ |
| Nur Austausch Sanit√§rartikel | ‚ùå | ‚ùå |
| Ohne Bad | ‚ùå | ‚ùå |

**Nachweis-Felder in Monday:**
- `color_mkt2e02p`: Nachweis Rohinstallation Elektrik
- `color_mkt2hpg0`: Nachweis Rohinstallation Sanit√§r
- `color_mkt2t435`: Nachweis Abdichtung Bad
- `color_mkt2t62x`: E-Check Protokoll

**Status-Werte f√ºr "Erledigt":** Fertig, Erledigt, Komplett, OK, Ja, Erstellt

---

## Telegram-Bot

### L053 - Telegram Webhook mit Supabase Edge Functions
**Datum:** 2026-01-29
**Kontext:** Telegram-Bot f√ºr neurealis Baustellen-Kommunikation
**L√∂sung:** Edge Function mit verify_jwt: false (Telegram braucht keinen JWT)
**Webhook-URL:** `https://{project}.supabase.co/functions/v1/telegram-webhook`
**Registrierung:**
```bash
curl "https://api.telegram.org/bot{TOKEN}/setWebhook?url={WEBHOOK_URL}"
```
**Bot-Token:** Als Secret in Supabase hinterlegen, NIEMALS in Code!

### L054 - Telegram Session-Management
**Datum:** 2026-01-29
**Kontext:** Mehrstufige Konversationen im Bot (z.B. Projekt √∂ffnen ‚Üí Mangel erfassen)
**L√∂sung:** `telegram_sessions` Tabelle mit:
- `aktuelles_bv_id` - Aktuell ge√∂ffnetes Projekt
- `aktueller_modus` - 'idle', 'mangel_erfassen', 'foto_upload', etc.
- `kontext` (JSONB) - Zwischenspeicher f√ºr mehrstufige Eingaben
**Pattern:** Session pro chat_id, bei jedem Update `last_activity` aktualisieren

---

## SharePoint-Sync

### L055 - SharePoint Delta-Queries f√ºr inkrementellen Sync
**Datum:** 2026-01-29
**Problem:** 90 GB SharePoint-Daten komplett zu synchen dauert ewig
**L√∂sung:** Microsoft Graph API Delta-Queries:
```typescript
// Erster Aufruf
GET /drives/{driveId}/root/delta

// Folge-Aufrufe mit deltaLink
GET {deltaLink aus vorheriger Response}
```
**Speicherung:** `sharepoint_sync_state` Tabelle f√ºr Delta-Links pro Site

### L056 - SharePoint-Sync: Videos nur verlinken
**Datum:** 2026-01-29
**Problem:** Videos (MP4, MOV) sind zu gro√ü f√ºr Supabase Storage
**L√∂sung:** Differenzierte Sync-Strategie:
- **Download:** PDF, DOCX, XLSX, JPG, PNG (< 50 MB)
- **Link-Only:** MP4, MOV, AVI + alle > 50 MB
**Implementierung:** `datei_url = NULL`, `sharepoint_link = Original-URL`

---

## Sicherheit / RLS

### L057 - 4-Stufen-Sicherheitskonzept f√ºr Dokumente
**Datum:** 2026-01-29
**Kontext:** SharePoint-Sites mit unterschiedlicher Vertraulichkeit
**L√∂sung:** `sicherheitsstufe` INTEGER (1-4) in dokumente-Tabelle:
| Stufe | Zugriff | Beispiel |
|-------|---------|----------|
| 1 | Alle Mitarbeiter | Projekte, Marketing |
| 2 | Bauleiter + GF | Preise, Vertrieb |
| 3 | GF + Buchhaltung | Finanzen |
| 4 | Nur GF | Personal, Management |
**RLS-Policy:** `WHERE sicherheitsstufe <= user_level`

---

## Claude Code / Subagenten (Fortsetzung)

### L058 - NIEMALS bestehende Edge Functions √ºberschreiben
**Datum:** 2026-01-29
**Problem:** Annahme dass Code √ºberschrieben wurde (war nicht der Fall - separate Functions)
**Regel:** Bei Edge Function Updates IMMER:

### L060 - Backups von Edge Functions erstellen
**Datum:** 2026-01-29
**Problem:** Edge Functions die nur in Supabase existieren k√∂nnen verloren gehen
**Regel:** VOR jeder √Ñnderung:
1. `mcp__supabase__get_edge_function` zum Abrufen des Codes
2. Backup speichern in `backups/edge-functions/[name]_v[version].ts`
3. Erst dann √Ñnderungen vornehmen
**Backup-Pfad:** `C:\Users\holge\neurealis-erp\backups\edge-functions\`
**Wichtig:** Auch wenn Function im lokalen Repo ist - Supabase-Version kann abweichen!

### L061 - Edge Functions Struktur verstehen
**Datum:** 2026-01-29
**Kontext:** Annahme dass telegram-webhook Bedarfsanalyse enthielt
**Wahrheit:** Bedarfsanalyse und Aufma√ü sind SEPARATE Edge Functions:
- `process-bedarfsanalyse` (v31) - OCR + Extraktion
- `process-aufmass-complete` (v29) - CSV‚ÜíExcel mit Styles
- `generate-aufmass-excel` (v20) - Excel-Generierung
- `telegram-webhook` (v46) - Nur Bot-Handler
**Regel:** Bei Edge Function Updates IMMER:
1. Bestehenden Code LESEN
2. Nur ERG√ÑNZEN, nicht ersetzen
3. Bestehende Befehle erhalten
**Konsequenz:** Funktionalit√§t verloren, musste neu implementiert werden

### L059 - Parallele Subagenten f√ºr komplexe Implementierungen
**Datum:** 2026-01-29
**Problem:** Gro√üe Implementierungen f√ºllen Context-Window
**L√∂sung:** 3+ parallele Subagenten f√ºr unabh√§ngige Aufgaben:
1. DB-Migrationen
2. Edge Function A
3. Edge Function B (im Hintergrund)
**Vorteil:** Jeder Agent hat eigenes Context-Window, Ergebnisse kompakt
**Best Practice:** `run_in_background: true` f√ºr lang laufende Tasks

---

## Edge Functions

### L052 - Edge Function Performance: Daten einmal laden
**Datum:** 2026-01-29
**Problem:** Edge Function l√§uft in WORKER_LIMIT wenn DB-Abfrage in Schleife
**Kontext:** `schlussrechnung-nachweis-check` lud Monday-Daten pro Schlussrechnung neu
**Ursache:** Supabase Edge Functions haben begrenzte Compute-Ressourcen
**L√∂sung:** DB-Abfragen VOR Schleife ausf√ºhren, dann in-memory filtern:
```javascript
// FALSCH: In Schleife
for (const item of items) {
  const data = await supabase.from('tabelle').select('*');  // N Abfragen!
  const match = data.find(x => x.id === item.id);
}

// RICHTIG: Einmal laden
const allData = await supabase.from('tabelle').select('*');  // 1 Abfrage
for (const item of items) {
  const match = allData.find(x => x.id === item.id);  // In-memory
}
```
**Ergebnis:** Function l√§uft erfolgreich statt WORKER_LIMIT Fehler

### L053 - Matching mit Typo-Toleranz
**Datum:** 2026-01-29
**Problem:** Exaktes String-Matching findet keine Treffer bei Tippfehlern in Daten
**Kontext:** Monday-Feld enth√§lt "Feininstallaiton" statt "Feininstallation"
**L√∂sung:** Prefix-Matching statt exaktem Match:
```javascript
// FALSCH: Exakt
if (text.includes('feininstallation')) { ... }

// RICHTIG: Prefix (toleriert Tippfehler am Ende)
if (text.includes('feininstall')) { ... }
```
**Regel:** Bei Matching gegen User-eingepflegte Daten Typo-Toleranz einbauen

---

## Subagenten-Koordination

### L054 - Subagenten √ºber Markdown-Dateien koordinieren
**Datum:** 2026-01-29
**Problem:** Parallele Subagenten f√ºllen das Haupt-Context-Window wenn sie direkt berichten
**L√∂sung:** Koordination √ºber zentrale Markdown-Datei:
1. **Tracker-Datei erstellen:** z.B. `docs/IMPLEMENTATION_TRACKER.md`
2. **Struktur:** Tasks mit Status (pending/in_progress/done/failed), Output-Pfade
3. **Subagenten lesen:** Tracker am Start, verstehen Gesamtkontext
4. **Subagenten schreiben:** Ergebnisse in separate Dateien, Status in Tracker updaten
5. **Hauptagent:** Liest nur Tracker f√ºr Fortschritt, Details bei Bedarf
**Vorteile:**
- Context-Window bleibt schlank
- Qualit√§t bleibt gleich (vollst√§ndiger Kontext in Dateien)
- Parallelisierung m√∂glich
- Nachvollziehbarkeit durch persistente Logs
**Pattern:**
```
docs/
‚îú‚îÄ‚îÄ IMPLEMENTATION_TRACKER.md  # Zentrale Koordination
‚îú‚îÄ‚îÄ implementation/
‚îÇ   ‚îú‚îÄ‚îÄ task1_output.md        # Subagent 1 Output
‚îÇ   ‚îú‚îÄ‚îÄ task2_output.md        # Subagent 2 Output
‚îÇ   ‚îî‚îÄ‚îÄ ...
```
**Regel:** Bei komplexen Multi-Step-Tasks IMMER Tracker-Datei verwenden

---

## Blog-Pipeline

### L062 - OpenAI Responses API vs. Chat Completions
**Datum:** 2026-01-29
**Problem:** OpenAI `/v1/responses` Endpoint mit `web_search_preview` gibt 400-Fehler
**Kontext:** blog-research sollte Web-Recherche via Responses API machen
**L√∂sung:** Standard Chat Completions API verwenden (`/v1/chat/completions`)
```javascript
// FALSCH: Responses API (gibt 400)
fetch('https://api.openai.com/v1/responses', {
  body: JSON.stringify({
    model: 'gpt-5.2',
    input: query,
    tools: [{ type: 'web_search_preview' }]
  })
});

// RICHTIG: Chat Completions API
fetch('https://api.openai.com/v1/chat/completions', {
  body: JSON.stringify({
    model: 'gpt-5.2',
    messages: [{ role: 'user', content: query }],
    max_completion_tokens: 2000
  })
});
```
**Hinweis:** Responses API ist f√ºr Agenten-Funktionalit√§t gedacht, aber web_search_preview funktioniert nicht zuverl√§ssig

### L063 - Edge Functions verify_jwt f√ºr interne Calls
**Datum:** 2026-01-29
**Problem:** Cron-Jobs und interne Function-Calls scheitern mit 401 wenn verify_jwt: true
**L√∂sung:** Bei Functions die intern oder via Cron aufgerufen werden: `verify_jwt: false`
```javascript
// Bei Deployment
await mcp__supabase__deploy_edge_function({
  name: 'blog-research',
  verify_jwt: false,  // <- Wichtig f√ºr Cron/interne Calls
  files: [...]
});
```
**Regel:**
- `verify_jwt: true` ‚Üí User-facing APIs (erfordern Supabase Auth)
- `verify_jwt: false` ‚Üí Cron-Jobs, interne Function-Calls, Webhooks

### L064 - Edge Function Timeouts bei Chain-Calls
**Datum:** 2026-01-29
**Problem:** Orchestrator ruft Editor‚ÜíResearch‚ÜíWriter sequentiell auf, Writer timeouted
**Kontext:** Jede Function braucht ~10-20s, Supabase Edge Function Timeout = 60s
**Symptom:** Einzelne Functions funktionieren, Chain scheitert
**M√∂gliche L√∂sungen:**
1. **Async/Callback-Pattern:** Orchestrator startet Tasks, pollt Status
2. **K√ºrzere Prompts:** Weniger Tokens pro Agent
3. **Background-Processing:** Queue-basierte Verarbeitung
4. **Timeout erh√∂hen:** Supabase Pro Plan (150s statt 60s)
**Regel:** Bei Multi-Agent-Chains: Max 2-3 sequentielle API-Calls pro Edge Function

### L065 - Supabase Cron mit pg_cron
**Datum:** 2026-01-29
**Kontext:** T√§gliche/w√∂chentliche Blog-Jobs einrichten
**L√∂sung:** `cron.schedule()` direkt in PostgreSQL
```sql
-- T√§glich um 8:00 UTC
SELECT cron.schedule(
  'blog-orchestrate-daily',
  '0 8 * * *',
  $$SELECT net.http_post(
    url := 'https://project.supabase.co/functions/v1/blog-orchestrate',
    headers := '{"Authorization": "Bearer ' || current_setting('app.supabase_service_role_key') || '"}'::jsonb,
    body := '{}'::jsonb
  );$$
);

-- Sonntags um 6:00 UTC
SELECT cron.schedule(
  'blog-crosslink-weekly',
  '0 6 * * 0',
  $$SELECT net.http_post(...);$$
);
```
**Verwaltung:** `SELECT * FROM cron.job;` f√ºr alle Jobs
**Deaktivieren:** `SELECT cron.unschedule('job-name');`

---

## Meta / Prozess

### L066 - Subagenten f√ºr Overnight-Tasks (KRITISCH)
**Datum:** 2026-01-29
**Problem:** Hauptchat-Kontext wurde mit Edge Function Code gef√ºllt, Context Window voll nach ~7 Stunden
**Urspr√ºngliche Anforderung:** User wollte autonome Overnight-Implementierung
**Was schief lief:**
1. Edge Functions direkt im Hauptchat geschrieben statt via Subagenten
2. Tracker-Datei erstellt, aber nicht konsequent genutzt
3. Hauptchat musste /compact ausf√ºhren ‚Üí Kontext-Verlust

**RICHTIGE Vorgehensweise f√ºr lange autonome Tasks:**
```
1. TRACKER-DATEI erstellen (z.B. docs/IMPLEMENTATION_TRACKER.md)
   - Alle Tasks mit IDs und Status (pending/in_progress/done)
   - Output-Pfade f√ºr jeden Task

2. PRO TASK einen SUBAGENTEN starten:
   Task-Tool mit subagent_type="general-purpose"
   Prompt: "Lies docs/IMPLEMENTATION_TRACKER.md, bearbeite Task TX,
            schreibe Output nach implementation/TX_output.md,
            aktualisiere Tracker wenn fertig."

3. HAUPTCHAT nur f√ºr:
   - Tracker lesen
   - Subagenten starten
   - Kurze Status-Updates

4. PARALLELE Subagenten wenn Tasks unabh√§ngig

5. BACKGROUND-MODE f√ºr lang laufende Tasks:
   run_in_background: true
```

**Vorteile:**
- Jeder Subagent hat eigenes Context Window
- Hauptchat bleibt schlank
- Nachvollziehbarkeit durch Output-Dateien
- Kann stundenlang ohne Context-Overflow laufen

**REGEL:** Bei Tasks > 2h IMMER dieses Pattern verwenden!

---

## Softr API

### L067 - Softr Tables API: Felder erstellen
**Datum:** 2026-01-29
**Kontext:** Erinnerungs-Felder mussten in Softr angelegt werden
**L√∂sung:** POST-Request an `/api/v1/databases/{db}/tables/{table}/fields`
```bash
curl -X POST "https://tables-api.softr.io/api/v1/databases/{DB_ID}/tables/{TABLE_ID}/fields" \
  -H "Softr-Api-Key: {API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Erinnerung Status",
    "type": "SELECT",
    "options": {
      "choices": [
        {"label": "Aktiv", "color": "#20956f"},
        {"label": "Pausiert", "color": "#727272"}
      ]
    }
  }'
```
**Unterst√ºtzte Typen:** SELECT, SINGLE_LINE_TEXT, NUMBER, DATETIME, etc.
**Einschr√§nkung:** PATCH f√ºr Feld-Updates wird NICHT unterst√ºtzt (nur f√ºr Records)

### L068 - 2-Phasen-Erinnerungslogik f√ºr M√§ngelmanagement
**Datum:** 2026-01-29
**Kontext:** NU soll Erinnerungen bekommen bis Foto hochgeladen, dann BL zur Abnahme
**L√∂sung:** Automatischer Phasenwechsel basierend auf `fotos_nachweis_nu`:
```
Phase 1 (NU-Erinnerung):
  Bedingung: erinnerung_status='Aktiv' UND fotos_nachweis_nu LEER
  ‚Üí E-Mail an NU alle 2 Tage

Phase 2 (BL-Erinnerung):
  Bedingung: fotos_nachweis_nu BEF√úLLT UND status_mangel ‚â† 'Abgenommen'
  ‚Üí E-Mail an Bauleiter alle 2 Tage

Stopp:
  - status_mangel enth√§lt 'Abgenommen' oder 'Abgeschlossen'
  - erinnerung_status = 'Pausiert' oder NULL
```
**Vorteil:** Kein manueller Statuswechsel n√∂tig, Foto-Upload triggert automatisch Phase 2
**Implementierung:** mangel-reminder v13 mit `hasNachweisPhoto()` Pr√ºfung

---

## MS365 Graph API

### L069 - Client Credentials Flow (Application Permissions)
**Datum:** 2026-01-29
**Problem:** refresh_token-basierter Flow erfordert User-Login
**L√∂sung:** Client Credentials Flow f√ºr Server-zu-Server:
```javascript
// Kein User-Login n√∂tig!
const response = await fetch(tokenUrl, {
  method: 'POST',
  body: new URLSearchParams({
    client_id: MS365_CLIENT_ID,
    client_secret: MS365_CLIENT_SECRET,
    scope: 'https://graph.microsoft.com/.default',
    grant_type: 'client_credentials',  // <-- Wichtig!
  }),
});
```
**Voraussetzung:** Application Permissions (nicht Delegated) + Admin Consent

### L070 - Graph API: 404 statt 403 bei Permission-Fehlern
**Datum:** 2026-01-29
**Problem:** Download gibt 404 obwohl Datei existiert
**Ursache:** Microsoft versteckt Existenz wenn Permissions fehlen (Sicherheits-Feature)
**Fazit:** Bei 404 IMMER auch Permissions pr√ºfen, nicht nur ob Datei existiert

### L071 - Admin Consent f√ºr Application Permissions
**Datum:** 2026-01-29
**Problem:** Application Permissions funktionieren nicht ohne Admin Consent
**L√∂sung:** Azure Portal ‚Üí App Registrations ‚Üí API Permissions ‚Üí "Administratorzustimmung erteilen"
**Rollen die Consent geben k√∂nnen:** Global Administrator, Cloud Application Administrator

---

## Cloud-Dienste / Performance

### L072 - PFLICHT: Batch API f√ºr langl√§ufige KI-Tasks
**Datum:** 2026-01-29
**Kontext:** Blog-Pipeline Writer-Schritt timeouted bei Supabase Edge Functions (60s Limit)
**REGEL:** Bei Cloud-Diensten (Supabase Edge Functions, Netlify Functions, etc.) IMMER Batch-Processing verwenden wenn:
1. API-Calls > 30 Sekunden dauern k√∂nnen
2. Mehrere Items verarbeitet werden
3. Kosten eine Rolle spielen (Batch ist 50% g√ºnstiger)

**OpenAI Batch API Pattern:**
```
1. SUBMIT: POST /batches mit JSONL-File von Requests
2. POLL: GET /batches/{id} alle 5-10 Min bis status='completed'
3. PROCESS: GET /files/{output_file_id}/content ‚Üí Ergebnisse verarbeiten
```

**Implementierung f√ºr Blog-Pipeline:**
```
blog-batch-submit: Erstellt Batch mit 5-10 Artikeln
blog-batch-poll: Cron alle 10 Min, pr√ºft Status
blog-batch-process: Verarbeitet fertige Ergebnisse
```

**Vorteile:**
- Kein Timeout-Problem (async Verarbeitung)
- 50% g√ºnstiger als synchrone API
- Skaliert auf 100+ Artikel/Tag
- Retry bei Fehlern automatisch

**Regel:** Bei JEDER neuen Integration mit KI/LLMs ZUERST pr√ºfen ob Batch-Processing m√∂glich

---

## Supabase Storage

### L073 - Storage-Bucket muss existieren
**Datum:** 2026-01-29
**Problem:** Edge Function Upload scheitert mit "Bucket not found"
**Kontext:** sharepoint-sync versuchte in `dokumente` Bucket zu schreiben, der nicht existierte
**L√∂sung:** VOR Deployment pr√ºfen ob Bucket existiert:
```javascript
// Buckets auflisten
const buckets = await mcp__supabase__list_storage_buckets();
// Bucket erstellen oder existierenden verwenden
```
**Debugging:** "Bucket not found" Fehler kommt vom Upload, nicht vom Download!
**Regel:** Bei neuen Edge Functions die Storage nutzen IMMER erst Buckets pr√ºfen

### L074 - Unique-Constraints bei generierten IDs
**Datum:** 2026-01-29
**Problem:** DB-Insert scheiterte mit Unique-Constraint-Verletzung
**Kontext:** `dokument_nr = SP-${item.id.substring(0, 8)}` - mehrere SharePoint-Items begannen mit `01VBIR76`
**Ursache:** 8 Zeichen zu wenig f√ºr Eindeutigkeit bei SharePoint-IDs
**L√∂sung:** Mehr Zeichen verwenden:
```javascript
// FALSCH: Nur 8 Zeichen
const dokumentNr = `SP-${item.id.substring(0, 8)}`;  // SP-01VBIR76 (Kollision!)

// RICHTIG: 16 Zeichen
const dokumentNr = `SP-${item.id.substring(0, 16)}`;  // SP-01VBIR76AYC2DRVZ (eindeutig)
```
**Regel:** Bei IDs aus externen Systemen: Mindestens 12-16 Zeichen f√ºr Eindeutigkeit

### L075 - Error-Handling f√ºr DB-Operationen in Edge Functions
**Datum:** 2026-01-29
**Problem:** Edge Function meldete Erfolg obwohl DB-Inserts scheiterten
**Kontext:** `itemsProcessed++` wurde IMMER erh√∂ht, auch wenn Insert fehlschlug
**L√∂sung:** Fehler pr√ºfen und z√§hlen:
```javascript
// FALSCH: Kein Error-Handling
await supabase.from('tabelle').insert(record);
result.itemsProcessed++;  // Z√§hlt auch bei Fehler!

// RICHTIG: Mit Error-Handling
const { error } = await supabase.from('tabelle').insert(record);
if (error) {
  result.errors++;
  result.errorDetails.push(`${item.name}: ${error.message}`);
  return;  // Nicht als Erfolg z√§hlen!
}
result.itemsProcessed++;
```
**Regel:** ALLE DB-Operationen in Edge Functions m√ºssen error-gepr√ºft werden

---

## Blog-Pipeline / Cornerstone-Content

### L076 - max_completion_tokens f√ºr lange Artikel
**Datum:** 2026-01-29
**Kontext:** 3000-W√∂rter Cornerstone-Artikel mit OpenAI Batch API
**Problem:** Artikel waren mit 4000 Tokens nur ~800-1200 W√∂rter
**L√∂sung:** Token-Limits nach Wortanzahl staffeln:
```javascript
// Wort-zu-Token Verh√§ltnis: ~1.3 Tokens pro Wort (Deutsch)
// 3000 W√∂rter ‚âà 4000 Tokens f√ºr Content
// + Strukturierung + Redundanz = 12000 Tokens sicher

const maxTokens = isCornerstone ? 12000 : 4000;
```
**Faustregel:** F√ºr 3000 W√∂rter ‚Üí mindestens 10.000-12.000 max_completion_tokens
**Ergebnis:** 2.999 W√∂rter erreicht (praktisch Zielwert)

### L077 - Cornerstone-Detection in Blog-Pipeline
**Datum:** 2026-01-29
**Kontext:** Unterscheidung normale Artikel vs. Pillar-Content
**L√∂sung:** Zwei Erkennungsmethoden:
1. **Explizit:** `cornerstone: true` Parameter beim Submit
2. **Automatisch:** `priority >= 100` in blog_keywords
**Implementierung:**
```javascript
const isCornerstone = cornerstone || kw.priority >= 100;
if (isCornerstone) {
  // L√§ngerer Prompt mit 10-Sektionen-Struktur
  // 12000 max_completion_tokens statt 4000
}
```
**Prompt-Struktur f√ºr Cornerstone:**
1. Einleitung (300 W√∂rter)
2. Definition & Abgrenzung (250 W√∂rter)
3. Kosten-√úberblick (400 W√∂rter)
4. Ablauf Schritt-f√ºr-Schritt (500 W√∂rter)
5. Lokaler Fokus Ruhrgebiet (300 W√∂rter)
6. F√∂rderungen & Finanzierung (300 W√∂rter)
7. H√§ufige Fehler (250 W√∂rter)
8. Checkliste (200 W√∂rter)
9. FAQ (300 W√∂rter)
10. Fazit + CTA (200 W√∂rter)

---

## WordPress REST API

### L078 - WordPress Application Passwords f√ºr API-Zugriff
**Datum:** 2026-01-29
**Kontext:** Blog-Artikel von Supabase nach WordPress synchronisieren
**L√∂sung:** WordPress Application Passwords (seit WP 5.6):
```javascript
// Basic Auth mit Application Password
const credentials = `${username}:${appPassword}`;
const authHeader = `Basic ${btoa(credentials)}`;

// POST erstellen
await fetch(`${wpUrl}/wp-json/wp/v2/posts`, {
  method: 'POST',
  headers: {
    'Authorization': authHeader,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    title: 'Titel',
    content: '<p>Inhalt</p>',
    status: 'publish',
    slug: 'mein-slug'
  })
});
```
**Erstellen:** WordPress Admin ‚Üí Benutzer ‚Üí Profil ‚Üí "Anwendungspassw√∂rter"
**Hinweis:** Generiertes Passwort nur einmal sichtbar!

### L079 - WordPress REST API: POST f√ºr Create und Update
**Datum:** 2026-01-29
**Problem:** Annahme dass PUT f√ºr Updates n√∂tig ist
**Wahrheit:** WordPress REST API verwendet POST f√ºr beides:
- `POST /wp-json/wp/v2/posts` ‚Üí Neuen Post erstellen
- `POST /wp-json/wp/v2/posts/{id}` ‚Üí Bestehenden Post aktualisieren
**Alternative:** PUT funktioniert auch f√ºr Updates, aber POST ist konsistenter

### L080 - WordPress Slug-basierte Duplikat-Pr√ºfung
**Datum:** 2026-01-29
**Kontext:** Pr√ºfen ob Blog-Post bereits in WordPress existiert
**L√∂sung:** Zwei-Schritt-Verfahren:
1. Wenn `wordpress_post_id` vorhanden: GET `/wp-json/wp/v2/posts/{id}`
2. Fallback: GET `/wp-json/wp/v2/posts?slug={slug}&status=any`
**Wichtig:** `status=any` um auch Entw√ºrfe und private Posts zu finden
**Ergebnis:** Keine Duplikate, bestehende Posts werden aktualisiert

---

## Supabase RLS

### L081 - RLS-Policies f√ºr anonyme User bei √∂ffentlichen Seiten
**Datum:** 2026-01-29
**Problem:** Marketing-Seite war leer obwohl 9 Blog-Posts existierten
**Ursache:** RLS-Policies nur f√ºr `authenticated` Rolle, Seite nutzt `anon` Key ohne Login
**L√∂sung:** Explizite Policy f√ºr anonyme Leser hinzuf√ºgen:
```sql
CREATE POLICY "Anon users can read blog_posts"
ON blog_posts FOR SELECT TO anon USING (true);
```
**Regel:** Bei √∂ffentlichen Seiten ohne Login IMMER pr√ºfen ob `anon` Rolle SELECT-Rechte hat

### L082 - WordPress Application Password User-Rollen
**Datum:** 2026-01-29
**Problem:** WordPress API gibt 401 "nicht berechtigt, Beitr√§ge zu erstellen"
**Ursache:** Der WordPress-User hat keine ausreichenden Rechte (nur "Abonnent" o.√§.)
**L√∂sung:** User muss mindestens Rolle "Redakteur" oder "Administrator" haben
**Pr√ºfung:** WordPress Admin ‚Üí Benutzer ‚Üí Rolle √§ndern
**Hinweis:** Application Password allein reicht nicht - der User dahinter braucht Schreibrechte

---

## IONOS Hosting

### L083 - IONOS stripped Authorization Header im CGI-Modus
**Datum:** 2026-01-29
**Problem:** WordPress REST API gibt 401 obwohl Credentials korrekt sind
**Ursache:** IONOS Apache l√§uft im CGI-Modus, der HTTP Authorization Header nicht an PHP weiterreicht
**Symptome:**
- Authentication funktioniert teilweise (Error "rest_cannot_create" statt "rest_not_logged_in")
- Gleiche Credentials funktionieren bei anderen Hostern
**M√∂gliche L√∂sungen:**
1. **Plugin:** "Application Password Workaround" oder "WP REST API Controller"
2. **IONOS Support:** PHP-Handler von CGI auf PHP-FPM umstellen lassen
3. **wp-config.php:** Alternative Auth-Header-Erkennung (erfordert FTP)
**Regel:** Bei IONOS-Hosting immer vorab pr√ºfen ob REST API Auth funktioniert

### L084 - .htaccess Auth-Fixes k√∂nnen 500 Error verursachen
**Datum:** 2026-01-29
**Problem:** Standard-.htaccess Fix f√ºr Authorization Header verursacht 500 Internal Server Error
**Kontext:** Versuch den Authorization Header via RewriteRule durchzureichen
**Code der scheiterte:**
```apache
<IfModule mod_setenvif.c>
SetEnvIf Authorization "(.*)" HTTP_AUTHORIZATION=$1
</IfModule>
<IfModule mod_rewrite.c>
RewriteEngine On
RewriteCond %{HTTP:Authorization} .
RewriteRule .* - [E=HTTP_AUTHORIZATION:%{HTTP:Authorization}]
</IfModule>
```
**Ursache:** Hoster-spezifische Apache-Konfiguration blockiert diese Direktiven
**L√∂sung:** Bei 500 Error sofort .htaccess zur√ºcksetzen, Alternative via Plugin w√§hlen
**Regel:** Vor .htaccess-√Ñnderungen IMMER Backup, bei Fehler sofort Rollback

---

## PDF-Generierung

### L085 - jsPDF-autotable: didDrawCell f√ºr gemischte Styles
**Datum:** 2026-01-30
**Problem:** jsPDF-autotable erlaubt keine verschiedenen Schriftarten/Farben innerhalb einer Zelle
**Kontext:** LV-Export ben√∂tigt: Name fett, Artikelnummer grau, Langtext normal
**L√∂sung:** `didDrawCell` Hook f√ºr manuelles Zeichnen mit Custom Styles:
```javascript
// 1. Daten-Map f√ºr strukturierte Infos pro Zeile
const positionDataMap = new Map();
positionDataMap.set(rowIndex, { bezeichnung, artikelnummer, langtext });

// 2. didDrawCell Hook √ºberschreibt automatischen Text
didDrawCell: (data) => {
  if (data.column.index === 1 && data.section === 'body') {
    const posData = positionDataMap.get(data.row.index);
    if (posData) {
      // Hintergrund √ºbermalen
      doc.rect(data.cell.x, data.cell.y, data.cell.width, data.cell.height, 'F');

      // Text mit verschiedenen Styles zeichnen
      doc.setFont('helvetica', 'bold');
      doc.text(posData.bezeichnung, x, y);

      doc.setFont('helvetica', 'normal');
      doc.setTextColor(120, 120, 120);
      doc.text(posData.artikelnummer, x, y + offset);
    }
  }
}
```
**Wichtig:** Placeholder-Text im Body f√ºr korrekte H√∂henberechnung beibehalten
**Regel:** Bei komplexem Cell-Styling immer `didDrawCell` statt inline Styles nutzen

---

## Excel-Import / LV-Synchronisation

### L086 - Excel-Dateien in Node.js parsen
**Datum:** 2026-01-30
**Problem:** Read-Tool kann keine bin√§ren Excel-Dateien (.xlsx) lesen
**L√∂sung:** Node.js Script mit `xlsx` Package:
```javascript
const XLSX = require('xlsx');
const workbook = XLSX.readFile(pfad);
const sheet = workbook.Sheets[workbook.SheetNames[0]];
const data = XLSX.utils.sheet_to_json(sheet, { header: 1 }); // Array of arrays
```
**Hinweis:** `header: 1` gibt rohe Arrays statt Objekte (wichtig f√ºr Spalten-Mapping)

### L087 - Artikelnummer-Transformation bei LV-Imports
**Datum:** 2026-01-30
**Problem:** Kunden-LVs haben andere Artikelnummern als neurealis-intern
**Beispiel GWS:**
- Kunden-Format: `01.01.1`, `01.01.2`
- neurealis-Format: `GWS.LV23-01.01.1`, `GWS.LV23-01.01.2`
**L√∂sung:** Transformations-Regel pro LV-Typ:
```javascript
// GWS: Pr√§fix hinzuf√ºgen
const dbArtNr = 'GWS.LV23-' + excelArtNr;

// Allgemein: Transformations-Map
const TRANSFORMATIONS = {
  'GWS': (nr) => 'GWS.LV23-' + nr,
  'VBW': (nr) => 'VBW-' + nr,
  'covivio': (nr) => 'CV24-' + nr,
};
```
**Fallback:** Wenn Artikelnummer nicht matcht ‚Üí Matching √ºber Bezeichnung (fuzzy)

### L088 - Doppeltes Matching bei LV-Imports
**Datum:** 2026-01-30
**Problem:** Artikelnummern k√∂nnen inkonsistent sein (Tippfehler, Format-√Ñnderungen)
**L√∂sung:** 2-stufiges Matching:
1. **Prim√§r:** Artikelnummer (mit Transformation)
2. **Fallback:** Bezeichnung/Artikelname (normalisiert, case-insensitive)
```javascript
// Normalisierung f√ºr Fallback-Matching
const normalize = (s) => s.toLowerCase()
  .replace(/[¬≤¬≥]/g, m => m === '¬≤' ? '2' : '3')
  .replace(/\s+/g, ' ')
  .trim();
```
**Regel:** Bei Fallback-Match immer Warnung ausgeben zur manuellen Pr√ºfung

---

## Telegram-Bot / M√§ngelmanagement

### L089 - Mangelnummer-Pattern f√ºr Bauleitung
**Datum:** 2026-01-30
**Kontext:** M√§ngel brauchen eindeutige, menschenlesbare Nummern
**L√∂sung:** Format `{PROJEKT_NR}-M{laufende_nummer}`:
```typescript
// Anzahl M√§ngel pro Projekt z√§hlen
const { count } = await supabase
  .from('maengel_fertigstellung')
  .select('id', { count: 'exact', head: true })
  .eq('projekt_nr', projektNr);

const nextNum = (count || 0) + 1;
return `${projektNr}-M${nextNum}`;  // z.B. ATBS-456-M1
```
**Vorteil:** Leicht zu kommunizieren auf Baustelle, eindeutig pro Projekt

### L090 - KI-Prompt f√ºr Gewerke-spezifische M√§ngel
**Datum:** 2026-01-30
**Problem:** KI erkannte M√§ngel nicht korrekt im Bau-Kontext
**L√∂sung:** Detaillierter System-Prompt mit:
1. **Gewerke explizit benennen:** Elektrik, Sanit√§r, Maler, Boden, T√ºren, Fenster, Heizung, Trockenbau, K√ºche
2. **TRENNUNGS-REGELN:** F√ºr Eingaben wie "Mangel 1: xyz, Mangel 2: abc"
3. **Typische M√§ngel-Beispiele:** Pro Gewerk (Steckdose locker ‚Üí Elektrik, Fliese gesprungen ‚Üí Sanit√§r)
4. **√úbersetzung:** Mehrsprachig (DE, RU, HU, RO, PL) ‚Üí Deutsche Ausgabe
**Regel:** Bei dom√§nenspezifischen KI-Tasks IMMER Fachvokabular im Prompt

### L091 - Multi-Mangel Foto-Workflow
**Datum:** 2026-01-30
**Problem:** Bei mehreren M√§ngeln wei√ü Bot nicht welchem Mangel das Foto geh√∂rt
**L√∂sung:** Zwei-Wege-Workflow:
1. **Mangel zuerst:** Nutzer w√§hlt Mangel aus ‚Üí dann Foto hochladen
2. **Foto zuerst:** Foto wird als pending gespeichert ‚Üí Auswahl-Buttons erscheinen
```typescript
// Pending Foto in Session speichern
modus_daten: {
  pending_foto: { url, file_id, uploaded_at },
  offene_maengel: [...]
}
```
**Callbacks:** `mangel:foto:{id}` (w√§hle Mangel f√ºr neues Foto), `mangel:assign:{id}` (weise pending Foto zu)
**Regel:** Bei n:1 Zuordnungen IMMER beide Richtungen unterst√ºtzen

### L092 - Bauvorhaben-Pflichtfelder bei Telegram-Bot-Eingaben
**Datum:** 2026-01-30
**Problem:** M√§ngel/Nachtr√§ge √ºber Telegram-Bot hatten keine BV-Informationen (projektname_komplett, projektname_extern)
**L√∂sung:** Bei JEDER Eingabe √ºber Telegram-Bot M√úSSEN folgende Felder bef√ºllt werden:
- `projektname_komplett` - Vollst√§ndiger BV-Name aus Monday
- `projektname_extern` (falls vorhanden) - Externer Projektname

**Daten-Quelle:** `monday_bauprozess` Tabelle
**JSON-Pfad f√ºr ATBS-Nummer:** `column_values->'text49__1'->>'text'`
**Projektname:** Feld `name` in `monday_bauprozess`

**Implementierung:**
```typescript
// Monday-Lookup bei Telegram-Bot Eingaben
const { data: monday } = await supabase
  .from('monday_bauprozess')
  .select('id, name, column_values');

const projekt = monday?.find(p => {
  const atbs = p.column_values?.['text49__1']?.text;
  return atbs === projektNr;
});

if (projekt) {
  record.projektname_komplett = projekt.name;
}
```

**Betroffene Tabellen:**
- `maengel_fertigstellung` ‚Üí projektname_komplett
- `nachtraege` ‚Üí projektname_komplett
- `fotos` ‚Üí projektname_komplett (falls vorhanden)

**Regel:** Telegram-Bot-Functions M√úSSEN Monday-Lookup f√ºr BV-Namen durchf√ºhren

---

### L093 - Softr-Sync: mangel_nr Feldmapping
**Datum:** 2026-01-30
**Problem:** mangel_nr wurde nicht zu Softr synchronisiert obwohl Wert in DB vorhanden
**Ursache:** Feld fehlte im FIELD_MAPPINGS in softr-sync Edge Function
**L√∂sung:** Softr-Feld-ID ermitteln und zu Mapping hinzuf√ºgen:
```typescript
'maengel_fertigstellung': {
  'mangel_nr': '1UqYa',  // <- Das fehlte!
  'datum_meldung': '2la7j',
  // ... weitere Felder
}
```
**Methode:** Via Softr API `/records/{id}` Beispiel-Record abrufen um Feld-ID zu finden
**Regel:** Bei neuen Feldern in Softr IMMER Feld-ID ermitteln und in softr-sync Mapping eintragen

### L094 - Dry-Run-Pflicht f√ºr LV-Imports
**Datum:** 2026-01-30
**Kontext:** GWS LV-Import mit 771 Positionen
**REGEL:** LV-Imports IMMER mit Dry-Run durchf√ºhren:
1. **Kategorisieren:** Preiserh√∂hungen, Preissenkungen, Neue, Kein Match
2. **Preissenkungen separat:** NIEMALS automatisch importieren
3. **User-Best√§tigung:** Vor echtem Import Zusammenfassung zeigen
4. **Backup:** Vor Import IMMER Backup der betroffenen Datens√§tze

**Dry-Run Kategorien:**
```
- Preiserh√∂hungen: Normal importieren nach Best√§tigung
- Preissenkungen: WARNUNG, einzeln best√§tigen oder √ºberspringen
- Neue Positionen: Gewerk-Zuordnung pr√ºfen
- √úberschriften: Automatisch ignorieren (Preis = 0)
- Kein Match: Protokollieren f√ºr manuelle Pr√ºfung
```
**Grund:** Preissenkungen k√∂nnen Kalkulationsfehler oder versehentliche Eingaben sein

### L095 - Fallback-Matching deaktivieren bei mehrdeutigen Positionen
**Datum:** 2026-01-30
**Problem:** Fallback-Matching √ºber Artikelname f√ºhrte zu falschen Zuordnungen
**Kontext:** "Stundenlohnarbeiten Facharbeiter" existiert 12x in Excel (pro Gewerk)
**Ursache:** Identischer Name, unterschiedliche Artikelnummern und Preise
**Symptom:** Fallback ordnete alle dem ersten DB-Treffer zu ‚Üí falsche Preise

**L√∂sung:** Fallback-Matching deaktivieren wenn:
1. Position mehrfach mit gleichem Namen vorkommt
2. Preise zwischen gleichnamigen Positionen stark variieren
3. Gewerk-spezifische Positionen existieren

**Regel:** Bei LV-Imports nur exaktes Artikelnummer-Matching verwenden
**Ausnahme:** Fallback nur nach expliziter User-Best√§tigung und Einzelpr√ºfung

---

## Telegram-Bot / Nachtrag-Erfassung

### L096 - Score-basiertes LV-Position-Matching
**Datum:** 2026-01-30
**Kontext:** Automatisches Matching von Nachtrag-Texten zu LV-Positionen
**L√∂sung:** Multi-Faktor-Scoring-Algorithmus:
```typescript
let score = 0;
if (gewerk === position.gewerk) score += 10;      // Gewerk-Match
for (const word of beschreibungWords) {
  if (positionName.includes(word)) score += 5;    // Wort-Match
}
// Keyword-Bonus f√ºr Fachbegriffe
if (keywords.some(kw => beschreibung.includes(kw))) score += 15;
// Threshold: score >= 10 f√ºr validen Match
```
**Vorteil:** Robustes Matching auch bei Tippfehlern und Variationen
**Regel:** Threshold niedrig genug f√ºr Treffer, hoch genug gegen False Positives

### L097 - Auftraggeber-Extraktion aus Monday-Projektnamen
**Datum:** 2026-01-30
**Kontext:** LV-Typ f√ºr Nachtr√§ge basierend auf Projekt ermitteln
**Problem:** Monday-Projektnamen haben Format "AG | Adresse | Details"
**L√∂sung:** Ersten Teil vor `|` extrahieren und normalisieren:
```typescript
const firstPart = projektName.split('|')[0].trim().toLowerCase();
if (firstPart === 'vbw') return 'VBW';
if (firstPart === 'gws') return 'GWS';
// ... weitere Mappings
return 'neurealis'; // Fallback
```
**LV-Typ Mapping:**
| Auftraggeber | LV-Typ |
|--------------|--------|
| VBW | VBW |
| GWS | GWS |
| Covivio | covivio |
| Vonovia | vonovia |
| Privat/neurealis | neurealis |
| WBG L√ºnen | WBG L√ºnen |

**Regel:** Fallback immer auf 'neurealis' f√ºr unbekannte Auftraggeber

---

## Embedding-basierte Suche

### L098 - Embedding-Suche vs. Score-basiertes Keyword-Matching
**Datum:** 2026-01-31
**Kontext:** Nachtrag LV-Position-Erkennung
**Problem:** Score-basiertes Keyword-Matching ist fragil (abh√§ngig von exakten Begriffen)
**L√∂sung:** Embedding-basierte Suche via `search_lv_positions` RPC mit pgvector
**Vorteile:**
- Semantische √Ñhnlichkeit statt exakter W√∂rter
- "Steckdose" findet auch "Wandsteckdose 2-fach"
- Robuster bei verschiedenen Formulierungen
**Threshold:** similarity >= 0.6 f√ºr qualifizierte Matches

### L099 - strip_html f√ºr saubere Embeddings
**Datum:** 2026-01-31
**Problem:** LV-Beschreibungen enthalten HTML-Tags (`<p>`, `<ul>`, `<li>`, etc.)
**Auswirkung:** HTML-Tags verf√§lschen Embeddings
**L√∂sung:** SQL-Funktion `strip_html()` und Client-Side Pendant:
```sql
CREATE OR REPLACE FUNCTION strip_html(text) RETURNS text AS $$
  SELECT COALESCE(regexp_replace($1, '<[^>]*>', ' ', 'g'), '');
$$ LANGUAGE sql IMMUTABLE;
```
**Anwendung:** `embedding_text = bezeichnung + ' - ' + strip_html(beschreibung)`

### L100 - Similarity-Threshold f√ºr LV-Matching
**Datum:** 2026-01-31
**Kontext:** Embedding-basierte LV-Position-Suche
**Threshold:** 0.6 (60%) ist guter Kompromiss
**Zu niedrig (< 0.5):** Zu viele False Positives (irrelevante Treffer)
**Zu hoch (> 0.8):** Zu viele False Negatives (relevante werden √ºbersehen)
**Regel:** Bei Unsicherheit lieber niedrigeren Threshold + manuelle Pr√ºfung

### L101 - CHECK constraints bei Telegram-Bot DB-Inserts
**Datum:** 2026-01-31
**Problem:** Nachtrag speichern scheiterte mit "Fehler beim Speichern"
**Ursache:** CHECK constraints in DB erlaubten nur bestimmte Werte:
- `nachtraege_status_check`: Nur `'(0) Offen / Preis eingeben'`, `'(1) Genehmigt'`, `'(2) Abgelehnt'`
- `nachtraege_gemeldet_von_check`: Nur `'bauleiter'`, `'nu'`
**L√∂sung:**
1. Code-seitig: Valide Status-Werte verwenden
2. DB-seitig: CHECK constraint erweitern wenn neue Werte n√∂tig
```sql
-- Neuen Wert zum CHECK hinzuf√ºgen
ALTER TABLE nachtraege DROP CONSTRAINT nachtraege_gemeldet_von_check;
ALTER TABLE nachtraege ADD CONSTRAINT nachtraege_gemeldet_von_check
  CHECK (gemeldet_von = ANY (ARRAY['bauleiter', 'nu', 'telegram']));
```
**Regel:** VOR dem Schreiben von Edge Functions CHECK constraints der Zieltabelle pr√ºfen!

### L102 - LV-Typen konsolidieren statt doppelt pflegen
**Datum:** 2026-01-31
**Problem:** "Privat" und "neurealis" waren separate LV-Typen mit √ºberlappenden Positionen
**Auswirkung:** Embedding-Suche f√ºr Nachtr√§ge fand nur Treffer im gefilterten LV-Typ
**L√∂sung:** LV-Typen zusammenf√ºhren:
```sql
UPDATE lv_positionen SET lv_typ = 'neurealis' WHERE lv_typ = 'Privat';
```
**Ergebnis:** 693 Positionen in "neurealis" (vorher 412 neurealis + 281 Privat getrennt)
**Regel:** Doppelte LV-Typen vermeiden - eine Preisliste pro Zielgruppe (B2B vs. B2C reicht)

---

## Vertrieb / LV-Kalkulation

### L103 - lv_positionen: preis vs. listenpreis
**Datum:** 2026-01-31
**Kontext:** Angebot aus Baubesprechungs-Transkription erstellt
**Problem:** Falscher Preis verwendet - Angebot war 41% zu niedrig
**DB-Struktur:**
- `preis` = EK (Einkaufspreis) - Was wir zahlen
- `listenpreis` = VK (Verkaufspreis) - Was der Kunde zahlt
**Beispiel:**
| Position | preis (EK) | listenpreis (VK) | Marge |
|----------|----------:|----------------:|------:|
| Wand-WC | 230,00 ‚Ç¨ | 352,13 ‚Ç¨ | +53% |
| Vinyl Planken/m¬≤ | 30,00 ‚Ç¨ | 37,04 ‚Ç¨ | +23% |
| E-Check | 332,47 ‚Ç¨ | 538,19 ‚Ç¨ | +62% |
**Regel:** Bei Angeboten an Auftraggeber (GWS, VBW, etc.) IMMER `listenpreis` verwenden!
**Fehlerfall:** EK-Angebot = sofortiger Verlust

### L104 - Transkription ‚Üí Angebot Workflow
**Datum:** 2026-01-31
**Kontext:** Plaud-Aufnahme einer Baubesprechung ‚Üí strukturiertes Angebot
**Workflow:**
1. **Transkription laden:** Plaud-App exportiert Gespr√§chsprotokoll
2. **Leistungen extrahieren:** KI erkennt Gewerke und Positionen aus nat√ºrlicher Sprache
3. **LV-Positionen zuordnen:** DB-Abfrage mit Artikelnummern und Listenpreisen
4. **Mengen sch√§tzen:** Aus Kontext (Wohnungsgr√∂√üe, R√§ume) ableiten
5. **HTML-Angebot generieren:** Mit Branding, Gewerks-Summen, Druckfunktion
**Zeitersparnis:** ~30 Minuten statt 2-3 Stunden manuell
**Wichtig:** Immer Preisspalte pr√ºfen (EK vs. VK) - siehe L103

---

## Hero API / LV-Bereinigung

### L105 - Hero GraphQL Soft-Delete f√ºr Artikel
**Datum:** 2026-01-31
**Kontext:** Bereinigung von 828 LV-Positionen (Duplikate, Alt-Versionen)
**L√∂sung:** `update_supply_product_version` Mutation mit `is_deleted: true`
```graphql
mutation {
  update_supply_product_version(
    supply_product_version: {
      product_id: "Ge7LKhFXgAA",
      is_deleted: true
    }
  ) { product_id }
}
```
**Hinweis:** Kein echtes DELETE - Soft-Delete f√ºr Audit-Trail
**Vorteil:** Wiederherstellung m√∂glich √ºber Backup + `is_deleted: false`

### L106 - Artikelnummer-Schema f√ºr neue Positionen
**Datum:** 2026-01-31
**Problem:** Generische Artikelnummern ("frei", "freie Position", leer) f√ºhren zu Duplikaten
**L√∂sung:** Schema `{Gewerk}-{Bauteil}-{Aspekt}` in Title Case:
- `Sanitaer-Dusche-Zulage`
- `Boden-Platten-Rueckbau`
- `Elektrik-Sat-Anschluss`
**Gewerke:** Elektrik, Sanitaer, Maler, Boden, Tueren, Fenster, Trockenbau, Kueche, Heizung, Allgemein
**Regel:** Keine Umlaute in Artikelnummern (ae, oe, ue statt √§, √∂, √º)

### L107 - LV-Duplikate: Immer h√∂heren Preis behalten
**Datum:** 2026-01-31
**Kontext:** 195 Positionen mit identischer Artikelnummer aber unterschiedlichen Preisen
**Entscheidung:** Bei Duplikaten IMMER den h√∂heren Preis behalten
**Grund:**
- Niedrigerer Preis = oft veraltet (Inflation, Materialkosten)
- H√∂herer Preis = aktueller Marktpreis
- Lieber zu hoch kalkuliert als zu niedrig (Marge!)
**Alternative:** Wenn niedrigerer Preis korrekt ist, manuell pr√ºfen und anpassen

### L108 - Hero LV-Datenqualit√§t: Typische Probleme
**Datum:** 2026-01-31
**Erkannte Muster bei Hero-Bereinigung:**
| Problem | Anzahl | L√∂sung |
|---------|--------|--------|
| DUPLIKAT-* Marker | 190 | L√∂schen |
| ALT-* mit alten Preisen | 436 | L√∂schen |
| Gleiche Nr, verschiedene Preise | 195 | H√∂heren behalten |
| Generische Nummern | 7 | Schema zuweisen |
| Gleiche Nr, verschiedene Produkte | 17 | Manuell korrigieren |
**Pr√§vention:** Bei neuen Positionen IMMER eindeutige Artikelnummer nach Schema vergeben

---

## Angebots-Erstellung / CPQ

### L109 - CPQ-Wizard Reihenfolge f√ºr Wohnungssanierung
**Datum:** 2026-01-30
**Kontext:** Konzept f√ºr Angebots-Erstellung aus Transkriptionen
**Optimale Reihenfolge:**
1. **Projekt** - ATBS-Nr, Kunde, Struktur (Gewerk vs. Raum)
2. **Positionen** - KI-Eingabe (Sprache/Text), Abh√§ngigkeiten automatisch
3. **Mengen** - Aufma√ü-basiert, R√§ume √ó Fl√§chen, Faktor/Prozent
4. **Kalkulation** - EK/VK/Marge, Zuschl√§ge, Profile
5. **Freigabe** - 4-Augen-Prinzip (GF)
6. **Versand** - PDF + E-Mail
**Grund:** Erst Inhalt (was), dann Menge (wie viel), dann Preis (was kostet's)
**Alternative verworfen:** Mengen w√§hrend Positionseingabe (zu un√ºbersichtlich)

### L110 - LV-Abh√§ngigkeiten aus Langtexten extrahieren
**Datum:** 2026-01-30
**Kontext:** Automatische Vorschl√§ge f√ºr verwandte Positionen
**Methode:** GPT-5.2 analysiert Langtexte nach Mustern:
- Explizite Verweise: "siehe Pos.", "gem. Pos.", "wie Pos.", "inkl. Pos."
- Zulagen: Positionen mit "Zulage" geh√∂ren zur Basis-Position
- Semantische √Ñhnlichkeit: Raufaser ‚Üí Untergrund + Streichen
**Speicherung:** `position_dependencies` Tabelle mit:
- `source_artikelnummer`, `target_artikelnummer`
- `dependency_type`: required, suggested, referenced_in_text
- `default_qty_factor`: z.B. 0.25 f√ºr "25% der Fl√§che"
**Vorteil:** Einmalige Analyse, dann schnelle Vorschl√§ge ohne KI-Kosten

### L111 - Aufma√ü-Mengen-Zuweisung UI-Pattern
**Datum:** 2026-01-30
**Kontext:** Mengen aus Aufma√ü f√ºr Angebotspositionen zuweisen
**UI-Layout:**
- Links: Position (z.B. "W√§nde streichen")
- Rechts: Tabelle mit R√§umen √ó Ma√ütypen (Wandfl√§che, Grundfl√§che, Umfang)
- Vorauswahl: Wandfl√§che alle R√§ume ‚úì, Bad ausgeklammert (Pauschale)
- Ein-/Ausklicken pro Raum
- Summe mit Faktor (z.B. 1.05 Verschnitt)
**Dokumentation im PDF:** "143,0 m¬≤ (Wohnzimmer, Schlafzimmer, K√ºche - Wandfl√§che)"
**Spezialf√§lle:**
- T√ºren: Anzahl R√§ume + 1 (Eingangst√ºr)
- Q2 25%: Wandfl√§che √ó 0.25 (Slider)

### L112 - Dokument-Nummernlogik mit Revisionen
**Datum:** 2026-01-30
**Kontext:** ANG/AB/NUA/RE Nummerierung
**Format:** `{ATBS}-{TYP}{LAUFEND}` z.B. ATBS-472-ANG01
**Revisions-Workflow:**
- ANG01 ‚Üí Kunde will √Ñnderungen ‚Üí ANG02 (neue Nummer!)
- Auftrag erteilt ‚Üí AB01 (basiert auf letztem ANG)
- NU ausgew√§hlt ‚Üí NUA01
- Fertigstellung ‚Üí RE01
**SQL-Funktion:** `get_next_dokument_nr('ATBS-472', 'ANG')` ‚Üí 'ATBS-472-ANG01'
**Regel:** Gleiche Angebotsnummer NIE wiederverwenden - immer neue Revision

### L113 - Pricing-Profile f√ºr Kundengruppen
**Datum:** 2026-01-30
**Kontext:** Verschiedene Kunden brauchen verschiedene Preisbasen
**L√∂sung:** Zwei Ebenen:
1. **Pricing-Profile:** "GWS Basis", "Privataufschlag 15%"
   - `base_lv_typ`: GWS, VBW, neurealis
   - `markup_percent`: Globaler Aufschlag
   - `per_trade_overrides`: Gewerk-spezifisch
2. **Kunde-Pricing:** Individuelle √úberschreibung
   - `default_profile_id`: Standard-Profil
   - `custom_markup_percent`: Nur f√ºr diesen Kunden
   - `target_margin`: Ziel-Marge
**Beispiel:** Privatkunde nutzt GWS-LV + 15% Aufschlag + Elektrik +20%
**Wichtig:** Aufschl√§ge NICHT im Stamm-LV speichern, sondern nur im Kundenprofil

### L114 - Raumgeometrien f√ºr Aufma√ü-Berechnung
**Datum:** 2026-01-30
**Kontext:** Aufma√ü f√ºr Angebote - nicht alle R√§ume sind rechteckig
**Raumtypen:**
| Typ | Eingabe | Wandfl√§che-Berechnung |
|-----|---------|----------------------|
| Rechteck | L √ó B √ó H | (L+B) √ó 2 √ó H |
| L-Form | Teilfl√§chen A+B, gemeinsame Wand | Au√üenumfang √ó H (gemeinsame 1√ó abziehen) |
| U-Form | Teilfl√§chen A+B+C, 2 gemeinsame W√§nde | Au√üenumfang √ó H |

**Gemeinsame W√§nde:**
- Bei L-Form: Innenwand zwischen Teil A und B
- Wird im Umfang nur 1√ó gez√§hlt (nicht 2√ó)
- Beispiel: L-Form mit gemeinsamer Wand 3m ‚Üí Umfang reduziert sich um 6m (2√ó3m)

**Abz√ºge:**
- T√ºren: ~2,0 m¬≤ pro T√ºr
- Fenster: variabel, manuell eingeben
- Werden von Wandfl√§che abgezogen

**JSONB-Struktur:**
```json
{
  "geometrie": "l_form",
  "teilflaechen": [{"name": "A", "laenge_m": 4.5, "breite_m": 3.0}],
  "gemeinsame_waende": [{"von": "A", "zu": "B", "laenge_m": 3.0}],
  "abzuege": {"tueren": {"anzahl": 1, "flaeche_m2": 2.0}}
}
```

---

## Edge Function Architektur

### L115 - Edge Function Timeout bei Batch-GPT-Calls
**Datum:** 2026-01-30
**Problem:** `analyze-lv-dependencies` Edge Function hatte 504 Gateway Timeout nach ~150s
**Ursache:** Supabase Edge Functions haben Hard-Limit von 150 Sekunden
**Kontext:** 300+ LV-Positionen in 10er-Batches = 30+ sequentielle GPT-Calls ‚Üí zu langsam
**L√∂sung:**
1. Pagination-Parameter hinzuf√ºgen (offset, limit)
2. Cron-Job mit mehreren kleinen Batches
3. Oder: Lokale Analyse via Claude Subagenten (kein Timeout)
**Faustregel:** Edge Functions maximal 50 Positionen pro Call

### L116 - Lokale Subagenten f√ºr lang laufende Analysen
**Datum:** 2026-01-30
**Kontext:** LV-Abh√§ngigkeiten-Analyse f√ºr 3 LV-Typen (GWS, VBW, neurealis)
**Problem:** Edge Function hat Timeout, aber Analyse muss vollst√§ndig sein
**L√∂sung:** Parallele Subagenten lokal starten:
- Kein Timeout-Limit
- Direkte DB-Zugriff via MCP
- Ergebnisse in Markdown dokumentieren
**Ergebnis:** 897 Positionen analysiert, 138 Abh√§ngigkeiten in ~5 Minuten

---

## LV / Angebots-CPQ

### L117 - LV-spezifische Gewerke-Namen sind inkompatibel
**Datum:** 2026-01-30
**Problem:** Generischer Prompt verwendet "Elektrik", aber GWS hat "Elektroarbeiten"
**Konsequenz:** Semantic Search mit Gewerk-Filter findet keine Treffer
**Vergleich:**
| LV-Typ | Gewerk-Beispiele |
|--------|------------------|
| GWS | Elektroarbeiten, Fliesen,u. Plattenarbeiten |
| VBW | Elektroarbeiten, Decken und W√§nde |
| neurealis | Elektro, Sonstiges |
| covivio | Duschwannen, Armaturen, Brausesets, Zubeh√∂r |
**L√∂sung:** Gewerke-Liste aus DB laden pro LV-Typ, nicht hardcoden

### L118 - Hybrid-Prompt-Ansatz f√ºr transcription-parse
**Datum:** 2026-01-30
**Kontext:** Ein Prompt f√ºr alle LV-Typen funktioniert schlecht
**L√∂sung:** Ein Template + LV-spezifische Parameter:
```typescript
const LV_CONFIGS = {
  GWS: {
    gewerke: ["Elektroarbeiten", "Fliesen,u. Plattenarbeiten", ...],
    besonderheiten: "Zulagen-Verweise, Positions-Verweise (wie vor)",
    qualitaeten: "Q2, Q3, Standard"
  },
  VBW: {
    gewerke: ["Heizung", "Decken und W√§nde", ...],
    besonderheiten: "Wohnungsgr√∂√üen-Staffeln (45/75/110 m¬≤)",
    qualitaeten: "Standard"
  }
};
```
**Vorteile:**
- Ein Prompt-Template wartbar
- Gewerke-Liste dynamisch aus DB
- LV-Besonderheiten werden ber√ºcksichtigt
**Tabelle:** `lv_config` f√ºr LV-spezifische Prompt-Parameter

### L119 - LV-Abh√§ngigkeiten: Quellen und Typen
**Datum:** 2026-01-30
**Kontext:** 138 Abh√§ngigkeiten aus LV-Analyse erstellt
**Dependency-Typen:**
| Typ | Bedeutung | Beispiel |
|-----|-----------|----------|
| `referenced_in_text` | Expliziter Verweis im Langtext | "zu Pos. 02.03.7" |
| `required` | Technisch zwingend | Fliesen ‚Üí Abdichtung (Nassraum) |
| `suggested` | Empfohlen | Raufaser ‚Üí Streichen |
| `often_together` | H√§ufig zusammen beauftragt | T√ºr + Zarge |
**Source-Feld:**
- `admin_rule`: Manuell gepflegt
- `text_analysis`: Automatisch aus Langtext
- `customer_rule`: Kundenspezifisch
- `learned`: Aus Rechnungshistorie (Phase 3)

---

## Angebots-CPQ Textbausteine

### L120 - Bedarfspositionen: Preise immer aus aktuellem LV
**Datum:** 2026-01-30
**Kontext:** Eventualpositionen (22.001-22.013) im Angebot
**Problem:** Kopierte Preise k√∂nnen veraltet sein
**L√∂sung:** Preise immer live aus `lv_positionen` laden, nicht statisch speichern
**Artikelnummern:** 22.001 (Abbruch Putz) bis 22.013 (Au√üenputz)
**Hinweistext im Angebot:**
> "Nach der Demontage k√∂nnen verdeckte Sch√§den sichtbar werden.
> Abrechnung erfolgt ausschlie√ülich nach tats√§chlichem Bedarf."

### L121 - NUA-Vertragswerk: 12 Paragraphen
**Datum:** 2026-01-30
**Kontext:** Vertragsbedingungen im NUA-PDF
**Struktur:**
- ¬ß1 Gegenstand (Leistungsumfang, Ansprechpartner, 13b UStG)
- ¬ß2 Vertragsbestandteile (Rangfolge)
- ¬ß3 Pauschalpreisvereinbarung
- ¬ß4 Nachtr√§ge (Partner-Portal Pflicht, Freigabe vor Ausf√ºhrung!)
- ¬ß5 Zahlungsbedingungen (7 Tage Vorschuss, 14 Tage Schluss)
- ¬ß6 Terminplan/Vertragsstrafen (0,25%/Tag, max 5%)
- ¬ß7 Abnahme
- ¬ß8 Kundenschutzklausel (12 Monate, 25.000‚Ç¨ Strafe)
- ¬ß9 Versicherungen (500k/250k/100k)
- ¬ß10 Nachweise (Gewerbe, Versicherung, MiLoG, 48b, 13b)
- ¬ß11 Fachnachweise (Partner-Portal Pflicht!)
- ¬ß12 M√§ngel (Partner-Portal Pflicht!)
**Wichtig:** Dreimal "Partner-Portal Pflicht" betont

---

## Blog-Qualit√§tsstandards

### L122 - Blog-Schreibstil f√ºr B2B-Vermieter
**Datum:** 2026-01-31
**Kontext:** √úberarbeitung des Leerstand-Artikels
**Problem:** KI-generierte Artikel wirken oft oberfl√§chlich und unprofessionell
**Qualit√§tsstandards:**
1. **Flie√ütext statt Bullet-Listen:** Gedankenfluss, nicht Aufz√§hlung
2. **Konkrete Zahlen:** Beispielrechnungen durchrechnen, nicht nur nennen
3. **Betriebswirtschaftliche Argumentation:** ROI, Amortisation, Opportunit√§tskosten
4. **Keine Plattit√ºden:** "Das spart Folgekosten" ‚Üí durch konkrete Euro-Betr√§ge ersetzen
5. **Fachbegriffe erlaubt:** B2B-Leser verstehen "Opportunit√§tskosten"
6. **USPs subtil integrieren:** Nicht als Werbung am Ende, sondern als logische L√∂sung
**Mindestanforderungen:**
- 1.500+ W√∂rter f√ºr Cornerstone-Artikel
- H2/H3-Struktur mit sinnvollen √úberschriften
- Praxisbezug: Konkrete Beispiele aus 280+ Projekten referenzieren

### L123 - 3-Block-Methode f√ºr Leerstandskalkulation
**Datum:** 2026-01-31
**Kontext:** Inhaltliches Framework f√ºr Vermieter-Artikel
**Problem:** Klassische "Miete √ó Monate" Rechnung untersch√§tzt Kosten um 30-50%
**L√∂sung:** Systematische 3-Block-Methode:
```
Block 1 - Laufende Fixkosten:
  ‚Üí Nicht umlagef√§higes Hausgeld (WEG)
  ‚Üí Grundsteuer (anteilig)
  ‚Üí Versicherungen
  ‚Üí Mindestbeheizung (12-14¬∞C Frostschutz)
  ‚Üí Verwaltung

Block 2 - Entgangene Mieteinnahmen:
  ‚Üí Marktmiete nach Wiedervermietung (nicht Altmiete!)
  ‚Üí Lokaler Mietspiegel als Referenz

Block 3 - Vermarktung & Risiko:
  ‚Üí Inserate, Fotos, Energieausweis
  ‚Üí Risikopuffer (1-2% Jahreskaltmiete)
```
**Rechenbeispiel 65m¬≤ NRW:**
- Block 1: 218 ‚Ç¨/Monat (Fixkosten)
- Block 2: 682,50 ‚Ç¨/Monat (10,50 ‚Ç¨/m¬≤)
- Block 3: 113,65 ‚Ç¨/Monat (Vermarktung + Risiko)
- **Gesamt: 1.014,15 ‚Ç¨/Monat** (vs. 682,50 ‚Ç¨ bei reiner Mietbetrachtung)

### L124 - Content-Tiefe statt Content-Breite
**Datum:** 2026-01-31
**Kontext:** Blog-Artikel-Qualit√§t verbessern
**Problem:** Oberfl√§chliche Artikel mit vielen Themen, aber wenig Substanz
**L√∂sung:** Lieber EIN Framework tiefgehend erkl√§ren als 7 Tipps oberfl√§chlich listen
**Beispiel Leerstand-Artikel:**
- **FALSCH:** "7 Tipps um Leerstandskosten zu senken" (generisch)
- **RICHTIG:** "3-Block-Methode zur vollst√§ndigen Kalkulation" (systematisch, umsetzbar)
**Vorteile:**
- Leser bekommt echtes Werkzeug statt Allgemeinpl√§tze
- Positioniert neurealis als Experte, nicht als Content-Farm
- Bessere Verweildauer, weil tats√§chlich n√ºtzlich

### L125 - CTA-Integration in Fachartikeln
**Datum:** 2026-01-31
**Kontext:** Wie wird CTA nicht aufdringlich?
**Regel:** CTA muss logische Konsequenz des Artikels sein, nicht Werbung
**Beispiel:**
- **FALSCH:** "Kontaktieren Sie neurealis f√ºr eine professionelle Sanierung!"
- **RICHTIG:** Nach Erkl√§rung der 3-Block-Methode:
  > "Sie m√∂chten Ihre Leerstandskosten analysieren lassen?
  > neurealis bietet eine kostenfreie Ersteinsch√§tzung mit Handlungsempfehlungen."
**Unterschied:** Der CTA bietet Hilfe bei dem, was gerade erkl√§rt wurde, nicht etwas anderes

---

## CPQ-System Implementierung

### L126 - Svelte 5 Type-Exports m√ºssen in separater Datei sein
**Datum:** 2026-01-31
**Problem:** TypeScript-Fehler beim Import von Typen aus .svelte Komponenten
**Kontext:** CPQ-Komponenten exportierten `export type Position = {...}` in .svelte Dateien
**Fehler:** `Module has no exported member 'Position'` beim Import
**L√∂sung:** Typen in separate `types.ts` Datei auslagern:
```typescript
// FALSCH: In .svelte Datei
<script lang="ts">
  export type Position = { id: string; ... };
</script>

// RICHTIG: Separate types.ts
// types.ts
export interface Position { id: string; ... }

// Component.svelte
import type { Position } from './types';
```
**Regel:** Shared Types IMMER in .ts Dateien, nicht in .svelte Komponenten

### L127 - 6 parallele Subagenten f√ºr gro√üe Features
**Datum:** 2026-01-31
**Kontext:** CPQ-System Implementierung (DB + Edge Function + UI + Komponenten + Daten + QA)
**Problem:** Sequential arbeiten f√ºllt Kontext-Window mit irrelevantem Suchprozess
**L√∂sung:** Task-Tool mit 6 parallelen Subagenten:
1. **T1:** DB-Schema (lv_config, angebots_bausteine, position_corrections)
2. **T2:** transcription-parse v2 (Hybrid-Prompt, Fallback, Lernen)
3. **T3:** UI-Wizard (8 Schritte, 3-Spalten Layout)
4. **T4:** Drag&Drop Komponenten (4 Svelte-Komponenten)
5. **T5:** Angebotsbausteine (44 Eintr√§ge bef√ºllen)
6. **T6:** Qualit√§tssicherung (TypeScript-Checks, Build)
**Koordination:** `docs/implementation/cpq_koordination.md` als zentrale Tracker-Datei
**Ergebnis:**
- Haupt-Kontext bleibt sauber (nur Koordination, keine Details)
- ~2 Stunden f√ºr komplettes Feature statt 6+ Stunden sequential
- Jeder Agent hat vollen Kontext f√ºr seinen Task
**Regel:** Bei Features mit 5+ separaten Komponenten IMMER parallele Subagenten verwenden

### L128 - Monday JSONB column_values ist verschachtelt
**Datum:** 2026-01-31
**Problem:** Projektauswahl zeigte "[object Object]" statt Projektnamen
**Ursache:** `monday_bauprozess.column_values` hat verschachtelte Struktur:
```json
{
  "status__1": {"text": "(0) Offen", "value": null},
  "text1__1": {"text": "Projektname", "value": null}
}
```
**Fehler:**
```javascript
// FALSCH: Gibt {text: "...", value: null} zur√ºck
const phase = row.column_values?.status__1;

// RICHTIG: Verschachtelung aufl√∂sen
const phase = row.column_values?.status__1?.text;
```
**Regel:** Bei JSONB-Feldern aus Monday IMMER `.text` f√ºr den Anzeigewert verwenden

### L129 - OpenAI response_format erfordert konsistenten Prompt
**Datum:** 2026-01-31
**Problem:** transcription-parse gab Status 400 zur√ºck
**Ursache:** Prompt sagte "Nur JSON-Array zur√ºckgeben" aber `response_format: { type: 'json_object' }` erzwingt ein Objekt
**L√∂sung:** Beides konsistent machen:
```javascript
// Prompt: "Antworte als JSON-Objekt mit Struktur: {\"positionen\": [...]}"
// UND
response_format: { type: 'json_object' }
```
**Regel:** Bei `response_format: json_object` muss der Prompt explizit ein Objekt verlangen, kein Array

---

## WordPress / IONOS

### L130 - IONOS X-WP-Auth Workaround f√ºr JWT
**Datum:** 2026-01-31
**Problem:** IONOS strippt Authorization Header, JWT-Plugin funktioniert nicht
**L√∂sung:** 3-stufiger Workaround:
1. **JWT Plugin installieren** + Secret Key in wp-config.php
2. **Custom Header nutzen:** `X-WP-Auth: Bearer {token}` statt `Authorization`
3. **wp-config.php erweitern:**
```php
// Am Anfang der wp-config.php
if (!empty($_SERVER['HTTP_X_WP_AUTH'])) {
    $_SERVER['HTTP_AUTHORIZATION'] = $_SERVER['HTTP_X_WP_AUTH'];
}
```
**Ergebnis:** WordPress REST API funktioniert vollst√§ndig auf IONOS
**Regel:** Bei IONOS immer X-WP-Auth Header statt Authorization verwenden

### L131 - WordPress API Discovery: 485 Routen in 22 Namespaces
**Datum:** 2026-01-31
**Kontext:** Vollst√§ndige API-Analyse von neurealis.de
**Wichtige Namespaces:**
- `wp/v2` (132 Routen) - Posts, Pages, Media, Categories
- `elementor/v1` (79 Routen) - Page Builder API
- `yoast/v1` (45 Routen) - SEO API
- `jwt-auth/v1` - Token Authentication
**Dokumentation:** `docs/wordpress_api/`
**Regel:** Vor WordPress-Integration API-Schema mit `/wp-json/` abrufen

### L132 - Elementor speichert Layouts in _elementor_data Post-Meta
**Datum:** 2026-01-31
**Kontext:** Versuch Elementor-Seiten per API zu erstellen
**Struktur:** `_elementor_data` enth√§lt JSON-Array mit Sections/Columns/Widgets
**Beispiel:**
```json
[{
  "elType": "section",
  "settings": {},
  "elements": [{
    "elType": "column",
    "settings": {"_column_size": 100},
    "elements": [{
      "elType": "widget",
      "widgetType": "heading",
      "settings": {"title": "Test", "header_size": "h1"}
    }]
  }]
}]
```
**Wichtig:** Zus√§tzlich `_elementor_edit_mode: "builder"` und `_elementor_template_type: "wp-page"` setzen
**Regel:** Elementor-Layouts aus bestehenden Seiten extrahieren und anpassen, nicht neu schreiben

### L133 - Yoast SEO Meta via _yoast_wpseo_* Post-Meta setzen
**Datum:** 2026-01-31
**Kontext:** SEO-Daten per API konfigurieren
**Wichtige Meta-Felder:**
- `_yoast_wpseo_title` - SEO Title (max 60 Zeichen)
- `_yoast_wpseo_metadesc` - Meta Description (150-160 Zeichen)
- `_yoast_wpseo_focuskw` - Focus Keyword
- `_yoast_wpseo_canonical` - Canonical URL
**API-Beispiel:**
```bash
curl -X POST "https://site.de/wp-json/wp/v2/posts/{id}" \
  -H "X-WP-Auth: Bearer $TOKEN" \
  -d '{"meta": {"_yoast_wpseo_metadesc": "Beschreibung hier"}}'
```
**Hinweis:** `yoast_head_json` im Response ist read-only, nur f√ºr Anzeige

### L134 - Subagenten-Koordination √ºber Tracker-Dateien
**Datum:** 2026-01-31
**Kontext:** 13 parallele Tasks f√ºr Blog-Optimierung
**Pattern:**
1. **Tracker-Datei erstellen:** `docs/implementation/BLOG_OPTIMIZATION_TRACKER_V2.md`
2. **Struktur:** Tasks mit Status (pending/done), Output-Pfade, Abh√§ngigkeiten
3. **Subagenten:** Lesen Tracker, schreiben in Output-Dateien, updaten Status
4. **Parallelisierung:** Unabh√§ngige Tasks gleichzeitig starten
**Vorteile:**
- Kontext-Window des Hauptchats bleibt schlank
- Nachvollziehbarkeit durch persistente Logs
- Skaliert auf 10+ parallele Aufgaben
**Regel:** Bei komplexen Multi-Step-Tasks IMMER Tracker-Datei verwenden

---

## Marketing / Blog-Qualit√§t

### L135 - Blog-Schreibstil f√ºr B2B-Vermieter
**Datum:** 2026-01-31
**Kontext:** Leerstand-Artikel war zu oberfl√§chlich
**Qualit√§tsstandards:**
- Professioneller Flie√ütext statt Bullet-Listen
- Konkrete Zahlen und Rechenbeispiele
- Mindestens 1.500 W√∂rter pro Artikel
- neurealis-USPs subtil einweben (nicht als Werbung)
- CTA als logische Konsequenz des Artikelinhalts
**Verboten:**
- Generische F√ºlls√§tze ("Es ist wichtig zu beachten...")
- Oberfl√§chliche Tipps ohne Tiefe
- Bullet-Listen wo Flie√ütext m√∂glich
**Regel:** Jeder Artikel muss einen konkreten Mehrwert bieten

### L136 - Komplettsanierung Kosten: 1.000-1.200 EUR/m¬≤
**Datum:** 2026-01-31
**Problem:** Eigenheim-Artikel hatte 682 EUR/m¬≤ (viel zu g√ºnstig!)
**Korrekte Preise 2026:**
- Komplettsanierung: **1.000-1.200 EUR/m¬≤**
- Badsanierung: 12.000-25.000 EUR
- Elektrik komplett: 80-120 EUR/m¬≤
- Heizungsanlage: 15.000-25.000 EUR
**Beispiel:** 110 m¬≤ Reihenhaus = **121.000 EUR** (nicht 75.000 EUR!)
**Regel:** Bei Preisangaben immer aktuelle Marktpreise verwenden, nicht zu g√ºnstig kalkulieren

### L137 - GPT-5.2 erfordert max_completion_tokens (best√§tigt)
**Datum:** 2026-01-31
**Problem:** Edge Function `transcription-parse` gab 400-Fehler bei GPT-5.2 Aufruf
**Ursache:** Parameter `max_tokens: 4000` wird von GPT-5.2 nicht unterst√ºtzt
**L√∂sung:** `max_completion_tokens: 4000` verwenden
```javascript
// FALSCH bei GPT-5.2
{ model: 'gpt-5.2', max_tokens: 4000 }

// RICHTIG bei GPT-5.2
{ model: 'gpt-5.2', max_completion_tokens: 4000 }
```
**Hinweis:** Dies best√§tigt L028, tritt aber auch mit `response_format: { type: 'json_object' }` auf
**Deployed:** transcription-parse v7

### L138 - Supabase FunctionsHttpError ist kein echtes Error-Objekt
**Datum:** 2026-01-31
**Problem:** `err instanceof Error` gibt `false` zur√ºck bei Supabase Function-Fehlern
**Kontext:** UI-Fehlerbehandlung zeigte "Analyse fehlgeschlagen" statt echte Fehlermeldung
**Ursache:** `supabase.functions.invoke()` gibt bei Fehlern ein `FunctionsHttpError` zur√ºck
**L√∂sung:** Robuste Fehlerbehandlungs-Funktion:
```typescript
function getErrorMessage(err: unknown): string {
  if (err instanceof Error) return err.message;
  if (typeof err === 'object' && err !== null) {
    if ('message' in err) return (err as any).message;
    if ('context' in err) return (err as any).context?.message;
    return JSON.stringify(err);
  }
  return String(err);
}
```
**Regel:** Bei Supabase Functions IMMER diese Pattern verwenden statt `err instanceof Error`

### L139 - pg_trgm f√ºr Fuzzy-Suche in PostgreSQL
**Datum:** 2026-01-31
**Kontext:** CPQ Hybrid-Suche: Erst Fuzzy, dann Embedding-Fallback
**Extension:** `CREATE EXTENSION IF NOT EXISTS pg_trgm;`
**GIN-Index:**
```sql
CREATE INDEX idx_bezeichnung_trgm ON lv_positionen USING GIN (bezeichnung gin_trgm_ops);
```
**Similarity-Funktion:** `similarity(bezeichnung, 'suchbegriff')` gibt 0-1 zur√ºck
**Threshold:** 0.3 ist guter Schwellenwert f√ºr sinnvolle Treffer
**Vorteil:** Findet auch Tippfehler und √§hnliche Schreibweisen

### L140 - Hierarchisches Lern-System f√ºr KI-Korrekturen
**Datum:** 2026-01-31
**Kontext:** CPQ-Lern-System soll aus Korrekturen lernen
**Problem:** Korrektur in GWS-Projekt soll auch bei VBW helfen
**L√∂sung:** 2-stufige Suche:
1. Erst im aktuellen `lv_typ` suchen
2. Falls keine Treffer: Globaler Fallback
3. Bei globalem Treffer: Bezeichnung als Hinweis nutzen, dann im aktuellen LV suchen
**R√ºckgabe:** `is_global_match` Flag zeigt Fallback-Status
**Vorteil:** Wissen wird LV-√ºbergreifend genutzt, aber lokale Treffer bevorzugt

---

## Meta / Prozess (STANDARD-ARBEITSWEISEN)

### L141 - Subagenten-Entwicklungsmodell f√ºr gr√∂√üere Projekte (STANDARD)
**Datum:** 2026-01-31
**Kontext:** CPQ-Verbesserungen erfolgreich mit 4 parallelen Subagenten implementiert
**PFLICHT f√ºr alle gr√∂√üeren Entwicklungsprojekte!**

**Modell:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HAUPTAGENT (PM)                          ‚îÇ
‚îÇ  - Koordination, Planung, √úbersicht                         ‚îÇ
‚îÇ  - Erstellt Koordinationsdatei mit Tasks                    ‚îÇ
‚îÇ  - Startet Subagenten parallel                              ‚îÇ
‚îÇ  - Sammelt Ergebnisse, aktualisiert Doku                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ‚îÄ‚Üí T1: DEV-BACKEND (Edge Functions, APIs)
          ‚îÇ
          ‚îú‚îÄ‚îÄ‚Üí T2: DEV-DATABASE (SQL, Migrationen, RPCs)
          ‚îÇ
          ‚îú‚îÄ‚îÄ‚Üí T3: DEV-UI (Frontend, Komponenten)
          ‚îÇ
          ‚îî‚îÄ‚îÄ‚Üí T4: QA-AGENT (Code-Review, Tests, Build)
                    ‚Üë Startet NACH T1-T3
```

**Ablauf:**
1. PM erstellt Koordinationsdatei (`docs/implementation/projekt_koordination.md`)
2. PM definiert Tasks mit klaren Aufgaben und Dateien
3. T1-T3 starten parallel (unabh√§ngige Arbeit)
4. T4 (QA) startet nach T1-T3 Abschluss
5. PM sammelt Ergebnisse, dokumentiert in logs.md

**Vorteile:**
- Parallele Entwicklung spart Zeit
- Klare Verantwortlichkeiten
- QA als Qualit√§tsgate vor Deployment
- Koordinationsdatei als Single Source of Truth

### L142 - Kontext-Schonung durch maximale Subagenten-Nutzung (STANDARD)
**Datum:** 2026-01-31
**PFLICHT: ALLES was ausgelagert werden kann, in Subagenten auslagern!**

**IMMER Subagenten nutzen f√ºr:**
| Aufgabe | Subagent-Typ |
|---------|--------------|
| Codebase durchsuchen | Explore |
| API-Dokumentation lesen | Explore |
| Mehrere Dateien analysieren | Explore |
| Code implementieren | general-purpose |
| SQL-Migrationen | general-purpose |
| Tests schreiben/ausf√ºhren | general-purpose |
| Build/Deploy | general-purpose |
| Web-Recherche | general-purpose |

**NUR im Hauptagent:**
- Koordination und Planung
- Kurze Datei-Reads (< 100 Zeilen)
- Kleine Edits (einzelne Zeilen)
- User-Kommunikation
- Dokumentation aktualisieren

**Parallele Subagenten:**
- Bei unabh√§ngigen Tasks: IMMER parallel starten
- Spart Zeit und schont trotzdem Kontext
- Beispiel: 3 DEV-Agents + 1 QA-Agent

**Ergebnis-Handling:**
- Subagenten geben kompakte Zusammenfassung zur√ºck
- Nur relevante Infos kommen ins Hauptfenster
- Details bleiben im Subagent-Kontext

**Warum wichtig:**
- Kontextfenster ist begrenzt (~200k Tokens)
- Lange Sessions f√ºllen Kontext schnell
- Subagenten haben eigenes Kontextfenster
- Ergebnisse kommen komprimiert zur√ºck

### L143 - Telegram media_group_id f√ºr Multi-Foto-Upload
**Datum:** 2026-01-31
**Problem:** Wenn User mehrere Fotos gleichzeitig sendet, werden sie einzeln verarbeitet
**L√∂sung:** `media_group_id` aus Telegram-Update nutzen:
```typescript
const mediaGroupId = update.message?.media_group_id;
if (mediaGroupId) {
  // Foto zur pending-Liste hinzuf√ºgen
  // Nach 1.5-2 Sekunden alle Fotos der Gruppe verarbeiten
}
```
**Wichtig:** Telegram sendet Gruppen-Fotos mit kurzer Verz√∂gerung einzeln - daher Timeout zum Sammeln n√∂tig

### L144 - Monday column_values Struktur variiert je nach Feldtyp
**Datum:** 2026-01-31
**Problem:** Monday-Spalten haben unterschiedliche JSON-Strukturen
**L√∂sung:** Flexible Extraktion mit Fallbacks:
```typescript
function extractFieldText(columnValues: any, ...fieldIds: string[]): string {
  for (const id of fieldIds) {
    const field = columnValues?.[id];
    if (!field) continue;
    // Verschiedene Strukturen pr√ºfen
    if (typeof field === 'string') return field;
    if (field.text) return field.text;
    if (field.value) return field.value;
    if (field.label) return field.label;
  }
  return '';
}
```

### L145 - Berechtigungs-Pr√ºfung f√ºr Telegram-Bot-Aktionen
**Datum:** 2026-01-31
**Kontext:** Nicht jeder soll alles √§ndern d√ºrfen (z.B. Termine, Status)
**L√∂sung:** Berechtigte E-Mails/Telegram-IDs in Code oder DB pflegen:
```typescript
const BERECHTIGTE = [
  'holger.neumann@neurealis.de',
  'dirk.jansen@neurealis.de'
];

async function istBerechtigt(chatId: number): Promise<boolean> {
  const { data: kontakt } = await supabase
    .from('kontakte')
    .select('email')
    .eq('telegram_chat_id', chatId)
    .single();
  return BERECHTIGTE.includes(kontakt?.email?.toLowerCase());
}
```
**Regel:** Bei kritischen Aktionen IMMER Berechtigung pr√ºfen

### L146 - Monday "Status | Projekt" ist status06__1 (nicht status__1)
**Datum:** 2026-02-01
**Problem:** Telegram-Bot fand keine Projekte bei Phasen-Auswahl
**Ursache:**
- Code las `status__1` ("(0) Offen") - das ist ein anderes Status-Feld!
- Richtig ist `status06__1` ("(0) Bedarfsanalyse", "(1) Angebotsphase", etc.)
**Monday hat 338 column_value Keys!** Viele haben √§hnliche Namen.
**Regel:** Monday-Spalten immer in DB verifizieren, nicht raten
**Debugging:**
```sql
SELECT DISTINCT column_values->'status06__1'->>'text', COUNT(*)
FROM monday_bauprozess
GROUP BY 1;
```

### L147 - JSONB-Felder in echte Spalten flattenen f√ºr Performance
**Datum:** 2026-02-01
**Problem:** JSONB-Zugriff `column_values->'key'->>'text'` ist umst√§ndlich und langsam
**L√∂sung:** Wichtige Felder als echte Spalten anlegen + bei Sync bef√ºllen
```sql
ALTER TABLE monday_bauprozess
ADD COLUMN atbs_nummer TEXT,
ADD COLUMN status_projekt TEXT;

UPDATE monday_bauprozess SET
  atbs_nummer = column_values->'text49__1'->>'text',
  status_projekt = column_values->'status06__1'->>'text';

CREATE INDEX idx_monday_status ON monday_bauprozess(status_projekt);
```
**Vorteile:**
- Einfachere Queries: `WHERE status_projekt LIKE '(2)%'`
- Index-Nutzung m√∂glich
- Code wird lesbarer: `projekt.atbs_nummer` statt `extractATBS(projekt.column_values)`
**Regel:** Bei > 5 JSONB-Zugriffen ‚Üí Flattening erw√§gen

### L148 - sync_source Spalte f√ºr bidirektionalen Sync
**Datum:** 2026-02-01
**Problem:** Bei bidirektionalem Sync (Monday ‚Üî Supabase) entstehen Loops
**L√∂sung:** `sync_source` Spalte mit Werten:
- `'monday'` - Daten kamen von Monday (Pull)
- `'supabase'` - Lokale √Ñnderung, noch nicht gepusht
- `'pending'` - Push gesendet, warte auf Best√§tigung
- `'synced'` - Best√§tigt synchron
**Logic:**
```typescript
// Pull: Nur updaten wenn nicht lokal ge√§ndert
if (existing.sync_source !== 'supabase') {
  await update(item, { sync_source: 'monday' });
}

// Push: Nur Items mit lokalen √Ñnderungen
const pending = await supabase
  .from('monday_bauprozess')
  .select('*')
  .eq('sync_source', 'supabase');
```

### L149 - Monday Status-Spalten nicht bidirektional pushen
**Datum:** 2026-02-01
**Problem:** Monday Status-Spalten haben strikt definierte Labels (z.B. "Raufaser & Anstrich", "Q2 & Anstrich")
**Fehler:** `ColumnValueException: This status label doesn't exist`
**Ursache:** Supabase-Werte wie "Keine" oder "Fertig" stimmen nicht mit Monday-Labels √ºberein
**L√∂sung:** Status-Spalten NUR Monday ‚Üí Supabase synchronisieren, nicht zur√ºck
**Sichere Spalten f√ºr Push:** Text, Number, Date, Link
**Unsichere Spalten:** Status/Color (color*, status*)

### L150 - Supabase .or() mit Spaltenvergleich funktioniert nicht
**Datum:** 2026-02-01
**Problem:** `.or('col_a.gt.col_b')` (Vergleich zweier Spalten) wird nicht unterst√ºtzt
**Versuch:**
```typescript
.or('sync_status.eq.pending_push,last_supabase_change_at.gt.last_monday_push_at')
```
**Ergebnis:** Kein Fehler, aber findet keine Ergebnisse
**L√∂sung:** Einfache Bedingung + JS-Filter:
```typescript
const { data } = await supabase
  .from('table')
  .select('*')
  .eq('sync_source', 'supabase');

const filtered = data.filter(item => {
  if (!item.last_monday_push_at) return true;
  return new Date(item.last_supabase_change_at) > new Date(item.last_monday_push_at);
});
```

### L151 - 3-Agenten-Modell f√ºr komplexe Implementierungen
**Datum:** 2026-02-01
**Kontext:** Monday Bidirektional Sync mit 3 parallelen Subagenten
**Architektur:**
- T1: Schema-Agent (Analyse, Mapping, Migration)
- T2: Sync-Agent (Edge Functions, Logik)
- T3: Trigger-Agent (DB-Trigger, Cron-Jobs)
**Vorteile:**
- Parallele Arbeit beschleunigt Implementierung
- Klare Zust√§ndigkeiten
- Einzelne Agent-Fehler blockieren nicht das Gesamtprojekt
**Lessons Learned:**
- Koordinationsdatei als Single Source of Truth
- Agent-Outputs pr√ºfen - manche Arbeit wurde trotz Crash fertig
- Manuelle Nacharbeit einplanen

### L152 - Monday Gewerk-Status-Spalten haben andere IDs als erwartet
**Datum:** 2026-02-01
**Problem:** Telegram-Bot Status-√Ñnderungen funktionierten nicht f√ºr manche Gewerke
**Ursache:** GEWERK_SPALTEN im Code hatte falsche Monday-Spalten-IDs (gg2On, 67n4J, etc.)
**L√∂sung:** Korrekte IDs aus MONDAY_COLUMN_MAPPING.md verwenden:
| Gewerk | Korrekte ID |
|--------|-------------|
| Elektrik | `color58__1` |
| Sanit√§r | `color65__1` |
| Maler | `color63__1` |
| Boden | `color8__1` |
| Tischler | `color98__1` |
| Entkernung | `color05__1` |
**Learning:** Immer docs/MONDAY_COLUMN_MAPPING.md als Referenz f√ºr Monday-Spalten-IDs verwenden!

### L153 - Sprach-Befehle ohne Projekt-Kontext erm√∂glichen
**Datum:** 2026-02-01
**Problem:** User mussten erst Projekt √∂ffnen bevor Sprach-Befehle funktionierten
**L√∂sung:** ATBS-Nummer aus Spracheingabe extrahieren und Projekt automatisch laden
**Implementierung:**
- `extractAtbsFromText()` erkennt ATBS-456, "456", "Projekt 456"
- `loadProjektByAtbs()` l√§dt Projekt aus DB
- `handleSprachBefehl()` nutzt Projekt aus Session ODER l√§dt es on-demand
**Benutzerfreundlichkeit:** "456 Elektrik fertig" funktioniert jetzt direkt aus Hauptmen√º

### L154 - pg_net Trigger ohne Auth bei verify_jwt=false
**Datum:** 2026-02-01
**Kontext:** DB-Trigger soll Edge Function aufrufen
**Problem:** Vault-Secret `service_role_key` existiert nicht ‚Üí Trigger-Funktion scheitert
**L√∂sung:** Wenn Edge Function `verify_jwt: false` hat, braucht pg_net keinen Auth-Header
**Implementierung:**
```sql
-- Vereinfachter Trigger OHNE Auth
PERFORM net.http_post(
  url := 'https://xxx.supabase.co/functions/v1/monday-push',
  headers := '{"Content-Type": "application/json"}'::jsonb,
  body := jsonb_build_object('item_id', NEW.id, 'triggered_by', 'db_trigger'),
  timeout_milliseconds := 30000
);
```
**Regel:** Bei internen Edge Functions (Trigger, Cron) immer `verify_jwt: false` + kein Auth-Header
**Vorteil:** Kein Vault-Secret n√∂tig, einfachere Konfiguration

### L155 - HTML‚ÜíPDF mit Puppeteer f√ºr User Guides
**Datum:** 2026-02-01
**Kontext:** Druckfertiger User Guide f√ºr Bauleiter erstellen
**Workflow:**
1. HTML mit CSS f√ºr Print erstellen (`@page`, `page-break-before`)
2. Puppeteer in Projekt installieren: `npm install puppeteer --save-dev`
3. PDF generieren:
```javascript
const page = await browser.newPage();
await page.goto('file://' + htmlPath);
await page.pdf({ path: 'output.pdf', format: 'A4', printBackground: true });
```
**Ergebnis:** `docs/TELEGRAM_BOT_USER_GUIDE.pdf` (2 Seiten A4, druckfertig)
**Tipp:** CSS `@media print` f√ºr saubere Seitenumbr√ºche

### L156 - Feature-Analyse mit 3 parallelen Subagenten
**Datum:** 2026-02-01
**Kontext:** Vollst√§ndige Telegram-Bot Feature-Analyse
**Architektur:**
- T1: Implementierte Features (Code analysieren)
- T2: Offene/geplante Features (Konzept-Dokumente vergleichen)
- T3: Neue Produktivit√§ts-Features (Business-Perspektive)
**Ergebnis:** √úbersichtliche Tabelle mit ‚úÖ/‚ùå Status + 15 neue Feature-Vorschl√§ge
**Learning:** 3 Perspektiven (Code, Konzept, Business) ergeben vollst√§ndiges Bild

### L157 - Nummerierungsformat f√ºr M√§ngel/Nachtr√§ge
**Datum:** 2026-02-01
**Kontext:** User-Feedback zu Dokumentennummern
**Gew√ºnscht:**
- M√§ngel: `ATBS-456-M1`, `ATBS-456-M2`
- Nachtr√§ge: `ATBS-456-N1`, `ATBS-456-N2`
**Aktuell (falsch):**
- M√§ngel: Keine automatische Nummer
- Nachtr√§ge: `NT-456-1` (falsches Pr√§fix)
**TODO:** Format korrigieren f√ºr konsistente Dokumentation

### L158 - Schritt-f√ºr-Schritt Dialog f√ºr User-Pr√§ferenzen
**Datum:** 2026-02-01
**Kontext:** Sync-Optimierung Konzept mit vielen Entscheidungen
**Problem:** Viele Fragen auf einmal √ºberfordern User (ADHS-freundlich!)
**L√∂sung:** AskUserQuestion mit einer Frage pro Bereich, sequentiell
**Workflow:**
1. Themenbereich identifizieren (SharePoint, Softr, Monday, etc.)
2. Eine Frage mit 3-4 Optionen stellen
3. Antwort speichern, n√§chste Frage
4. Am Ende: Alle Entscheidungen zusammenfassen
**Vorteile:**
- User bleibt fokussiert
- Klare Entscheidungspunkte
- Keine √úberladung
**Anwendung:** Komplexe Architektur-Entscheidungen, Konzeptplanung, Feature-Priorisierung

### L159 - Last-Write-Wins f√ºr bidirektionalen Sync
**Datum:** 2026-02-01
**Kontext:** Softr ‚Üî Supabase Konfliktl√∂sung
**Problem:** Beide Systeme k√∂nnen gleichzeitig Daten √§ndern
**L√∂sungsoptionen:**
1. Master gewinnt (einfach, aber unfair)
2. Last-Write-Wins (fair, braucht Timestamps)
3. Merge (komplex, fehleranf√§llig)
**Gew√§hlt:** Last-Write-Wins
**Implementierung:**
```sql
-- Bei Pull: Nur √ºberschreiben wenn remote neuer
IF remote.updated_at > local.updated_at THEN UPDATE;
-- Bei Push: Immer pushen, remote pr√ºft Timestamp
```
**Ben√∂tigt:** `last_modified_at` Spalte in allen sync-relevanten Tabellen
**Risiko:** Clock-Skew zwischen Systemen ‚Üí UTC √ºberall verwenden

### L160 - SharePoint Sites via MS Graph API katalogisieren
**Datum:** 2026-02-01
**Kontext:** Alle SharePoint-Sites scannen und dokumentieren
**Endpoint:** `GET https://graph.microsoft.com/v1.0/sites?search=*`
**Ergebnis:**
- 49 Sites gefunden (neurealis.de Tenant)
- 12 Wohnungssanierung-Sites relevant
- Gr√∂√üte: Wohnungssanierung-Projekte (69,66 GB)
**Edge Function:** `sharepoint-sites` mit `?action=list-sites`
**Tipp:** Speicherquoten via `/sites/{siteId}/drives` abrufen

### L161 - SharePoint Ordnerstruktur-Muster (Projektordner)
**Datum:** 2026-02-01
**Kontext:** Standard-Struktur f√ºr Projekt-Dokumentation
**Erkanntes Muster (00 Vorlage):**
```
01 Angebot - SUB
02 Angebot - Kunde
03 Auftrag
05 Nachtr√§ge
06 Rechnung - Kunde
07 Rechnung - SUB
10 Fotos
15 Einkauf
20 E-Check
30 Qualit√§tssicherung
```
**Nutzung:** 60% der Projekte mit ATBS-Nummer, 55% mit ISO-Datum
**Inkonsistenzen:** Auftraggeber-Schreibweise (`gws` vs `GWS`), Projekte ohne ATBS

### L162 - SharePoint Delta-Query braucht Initial-Sync pro Site
**Datum:** 2026-02-01
**Kontext:** SharePoint-Sync mit Delta-Queries f√ºr inkrementelle Updates
**Problem:** 11 von 12 Sites hatten keinen `sync_state` ‚Üí 0% synchronisiert
**Ursache:** Delta-Query braucht initialen Full-Sync um `delta_link` zu erhalten
**L√∂sung:** Pro Site einmal `?action=sync&site=/sites/[SiteName]` aufrufen
**Warnung:** Bei 112 GB Gesamtvolumen dauert Initial-Sync mehrere Stunden
**Empfehlung:** Sites nacheinander synchronisieren, nicht alle parallel

---

### L170 - ER-NU-* Dokumente Vollst√§ndigkeitspr√ºfung
**Datum:** 2026-02-02
**Kontext:** Analyse fehlender NU-Rechnungen in Softr/Supabase
**Methode:** Vergleich ER-Zahl (Zahlungsausg√§nge) mit ER-NU (Rechnungsdokumente)
**Ergebnis:**
- 114 ER-NU-* alle mit ATBS-Nummer ‚úÖ
- 18 Projekte (Phase 5-7) OHNE ER-NU trotz abgeschlossener Arbeiten
- 4 Projekte mit 56.302 ‚Ç¨ bezahlt OHNE Rechnungsdokument
**Kritische ATBS:** 437, 449, 429, 405
**Query-Pattern:**
```sql
-- Zahlungen ohne zugeh√∂rige Rechnung finden
WITH zahlungen AS (SELECT ... FROM softr_dokumente WHERE art_des_dokuments LIKE 'ER-Zahl%'),
er_nu_docs AS (SELECT ... FROM softr_dokumente WHERE art_des_dokuments LIKE 'ER-NU-%')
SELECT z.* FROM zahlungen z LEFT JOIN er_nu_docs e ON z.atbs_nummer = e.atbs_nummer WHERE e.er_nu_nr IS NULL;
```

### L171 - Rechnungsnummern aus Verwendungszweck extrahieren
**Datum:** 2026-02-02
**Kontext:** NU-Rechnungsnummern stehen im Verwendungszweck der Zahlungen
**Muster:** `ReNr [Nummer]` oder `ReNr: [Nummer]` im `notizen` Feld
**Regex:** `'ReNr[:\s]*([A-Z0-9\-]+)'`
**Beispiele aus ER-Zahl:**
- `ReNr RE20250111` ‚Üí MENNZA GMBH
- `ReNr 1189` ‚Üí Antonio Pepe
- `ReNr 59-2025` ‚Üí ION WEBER
**Anwendung:** Automatische Zuordnung von Zahlungen zu Rechnungen

### L172 - NUs senden Rechnungen NICHT per E-Mail mit PDF
**Datum:** 2026-02-02
**Kontext:** E-Mail-Sync mit 625 E-Mails durchsucht
**Befund:** MENNZA, Antonio Pepe, ION WEBER, TOP HANDWERKER senden keine PDF-Anh√§nge
**E-Mails von NUs:** Nur Widerspr√ºche, M√§ngelr√ºckmeldungen, Support-Anfragen
**Konsequenz:** NU-Rechnungen m√ºssen in SharePoint oder Hero gesucht werden
**Alternative Quellen:**
- SharePoint: `/sites/Wohnungssanierung-Finanzen/50 Eingangsrechnungen/`
- Hero Software: Dokumenten-Upload im Projekt

### L173 - SharePoint Finanzen-Site f√ºr Eingangsrechnungen
**Datum:** 2026-02-02
**Kontext:** Wo liegen NU-Rechnungen in SharePoint?
**Sites:**
- `Wohnungssanierung-Finanzen` (1,81 GB) - ‚ùå noch nicht synchronisiert
- `Wohnungssanierung-Projekte` (69,66 GB) - ‚ùå noch nicht synchronisiert
**Ordnerstruktur (erwartet):**
```
/sites/Wohnungssanierung-Finanzen/
‚îî‚îÄ‚îÄ 50 Eingangsrechnungen/
    ‚îî‚îÄ‚îÄ 2025/
        ‚îî‚îÄ‚îÄ [Lieferant]/[ReNr].pdf
```
**Aktion:** Finanzen-Site synchronisieren f√ºr ER-NU-Import

### L174 - Markdown‚ÜíElementor Konvertierung via Edge Function
**Datum:** 2026-02-02
**Kontext:** WordPress Elementor-Seiten automatisch aus Markdown bef√ºllen
**Edge Function:** `wordpress-update-elementor` v2
**Mapping:**
| Markdown | Elementor |
|----------|-----------|
| `# Titel` | Page Title + Slug |
| `## Kapitel` | Section + Heading Widget (h2) |
| `### Abschnitt` | `<h3>` im Text Editor Widget |
| Abs√§tze | `<p>` Tags im editor-Setting |
**Wichtig:**
- Elementor-Daten werden in `meta._elementor_data` als JSON-String gespeichert
- `_elementor_edit_mode: 'builder'` aktiviert Elementor f√ºr die Seite
- X-WP-Auth Header f√ºr IONOS-Kompatibilit√§t (L130)
- Section-IDs m√ºssen 8 Zeichen hex sein (zuf√§llig generiert)
**Struktur:**
```json
[{
  "id": "8_zeichen_hex",
  "elType": "section",
  "settings": { "layout": "boxed" },
  "elements": [{
    "elType": "column",
    "elements": [
      { "widgetType": "heading", "settings": { "title": "..." } },
      { "widgetType": "text-editor", "settings": { "editor": "<p>...</p>" } }
    ]
  }]
}]
```
**Anwendung:** `node scripts/update_elementor.mjs update`

---

*Aktualisiert: 2026-02-02*
